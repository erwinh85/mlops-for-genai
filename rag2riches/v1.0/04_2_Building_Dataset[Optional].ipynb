{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "metadata": {
        "id": "Wz0zOn_GI7bQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [Building Data for Multimodal Question-Answering System]\n",
        "\n",
        "[Change the link]\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_1_5_flash.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fgemini%2Fgetting-started%2Fintro_gemini_1_5_flash.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
        "    </a>\n",
        "  </td>    \n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/getting-started/intro_gemini_1_5_flash.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_1_5_flash.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n"
      ],
      "metadata": {
        "id": "laG9A9JMI9Hr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview\n",
        "\n",
        "[add overview]"
      ],
      "metadata": {
        "id": "jarpUZKLJIm0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[add what you learned in previous notebook and link] - skip if its first\n",
        "\n",
        "\n",
        "[Context of this notebook compared to overall idea]"
      ],
      "metadata": {
        "id": "jUe-0H73JLDI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting Started"
      ],
      "metadata": {
        "id": "8t0pckqNJNvk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Dependencies\n"
      ],
      "metadata": {
        "id": "X5t2fqYfJPv4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70jxt3ckr_tF",
        "outputId": "f6919b40-fa45-41fb-d3a9-be352fa7cdff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/5.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/5.1 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33m  WARNING: The script tb-gcp-uploader is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "! pip3 install --upgrade --user --quiet google-cloud-aiplatform"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Restart runtime\n",
        "\n",
        "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which restarts the current kernel."
      ],
      "metadata": {
        "id": "Km6_hsqGJStw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    import IPython\n",
        "\n",
        "    app = IPython.Application.instance()\n",
        "    app.kernel.do_shutdown(True)"
      ],
      "metadata": {
        "id": "U4EZcC_-sCPz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. ⚠️</b>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "xM3FCVq4JVVT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "If you are running this notebook on Google Colab, run the cell below to authenticate your environment.\n"
      ],
      "metadata": {
        "id": "ju8zRjSUJXbA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set Google Cloud project information and initialize Vertex AI SDK\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
        "\n",
        "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ],
      "metadata": {
        "id": "VhwNQHrPJbEH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ],
      "metadata": {
        "id": "27DlnJX_sFpk"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define project information\n",
        "PROJECT_ID = \"\"  # @param {type:\"string\"}\n",
        "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
        "BUCKET_NAME = \"mlops-for-genai\" # @param {type:\"string\"}\n",
        "# Initialize Vertex AI\n",
        "import vertexai\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "\n",
        "# Initialize cloud storage\n",
        "from google.cloud import storage\n",
        "\n",
        "storage_client = storage.Client(project=PROJECT_ID)\n",
        "bucket = storage_client.bucket(BUCKET_NAME)"
      ],
      "metadata": {
        "id": "2S1-P058sPbL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import libraries\n"
      ],
      "metadata": {
        "id": "CzhLTjLvJfIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython.display\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "from vertexai.generative_models import (\n",
        "    GenerationConfig,\n",
        "    GenerativeModel,\n",
        "    HarmBlockThreshold,\n",
        "    HarmCategory,\n",
        "    Part,\n",
        ")\n",
        "from typing import List\n",
        "from google.cloud.storage import Bucket\n",
        "import json\n",
        "import pandas as pd\n",
        "import os"
      ],
      "metadata": {
        "id": "oQNRQncCsP-d"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the models\n",
        "\n",
        "To learn more about all [Gemini API models on Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-models).\n"
      ],
      "metadata": {
        "id": "-eefl9rrJh3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_ID_PRO = \"gemini-1.5-pro-001\"  # @param {type:\"string\"}\n",
        "MODEL_ID_FLASH = \"gemini-1.5-flash-001\" # @param {type:\"string\"}\n",
        "\n",
        "model_pro = GenerativeModel(MODEL_ID_PRO)\n",
        "model_flash = GenerativeModel(MODEL_ID_FLASH)"
      ],
      "metadata": {
        "id": "Gn05MyADsST2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Add data path"
      ],
      "metadata": {
        "id": "WCTAzZokJkFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prototype_data = \"multimodal-finanace-qa/data/unstructured/prototype/\"  # @param {type:\"string\"}\n",
        "production_data = \"multimodal-finanace-qa/data/unstructured/production/\"  # @param {type:\"string\"}"
      ],
      "metadata": {
        "id": "h8FhKlFWsYCO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Manual Review Process for Multimodal RAG Question-Answer-Citation Pairs\n",
        "\n",
        "**SME Review (1-5 SMEs)**\n",
        "\n",
        "**Thorough Review:**\n",
        "\n",
        "*   **Answer Quality:**  Assess if the generated answer is the most accurate and comprehensive representation of the expected response. Modify if necessary.\n",
        "    *   **Voting:**\n",
        "        *   **Accurate (1/0):** Indicate whether the answer is accurate and relevant.\n",
        "        *   **Comprehensive (1/0):** Indicate whether the answer is comprehensive and addresses all aspects of the question.\n",
        "        *   **Well-written (1/0):** Indicate whether the answer is well-written and easy to understand.\n",
        "\n",
        "*   **Question Clarity:** Evaluate if the generated question effectively captures the intended query. Refine if needed.\n",
        "    *   **Voting:**\n",
        "        *   **Clear (1/0):** Indicate whether the question is clear and unambiguous.\n",
        "        *   **Relevant (1/0):** Indicate whether the question is relevant to the context.\n",
        "        *   **Concise (1/0):** Indicate whether the question is concise and to the point.\n",
        "\n",
        "*   **Citation Validity:** Verify the authenticity and relevance of the provided citation.\n",
        "    *   **Voting:**\n",
        "        *   **Authentic (1/0):** Indicate whether the citation is from a reliable source.\n",
        "        *   **Relevant (1/0):** Indicate whether the citation supports the answer.\n",
        "        *   **Accessible (1/0):** Indicate whether the citation is easily accessible.\n",
        "\n",
        "*   **Question Type Alignment:** Confirm that the assigned 'question_type' accurately reflects the nature of the generated question.\n",
        "    *   **Voting:**\n",
        "        *   **Accurate (1/0):** Indicate whether the question type is accurate.\n",
        "\n",
        "*   **Compliance & Policy Adherence:** Flag any question-answer-citation pairs that violate internal compliance guidelines, policies, or expectations.\n",
        "    *   **Voting:**\n",
        "        *   **Compliant (1/0):** Indicate whether the pair adheres to internal policies.\n",
        "        *   **Sensitive Content (1/0):** Indicate whether the pair contains sensitive or offensive content.\n",
        "        *   **Bias (1/0):** Indicate whether the pair exhibits any bias.\n",
        "\n",
        "*   **Strategies & Policies Adherence:** Evaluate if the question-answer-citation pair aligns with the defined strategies and policies for RAG data generation.\n",
        "    *   **Voting:**\n",
        "        *   **Adheres to Strategies (1/0):** Indicate whether the pair aligns with the defined strategies.\n",
        "        *   **Adheres to Policies (1/0):** Indicate whether the pair adheres to the defined policies.\n",
        "\n",
        "**Additional Voting for all methods**\n",
        "\n",
        "*   **Drop (1/0):** Indicate whether the pair should be discarded entirely.\n",
        "*   **Modify (1/0):** Signal if the pair requires modification.\n",
        "*   **Correct Citation (1/0):** Specify if the citation needs correction.\n",
        "*   **Confidence (1-5):** Indicate the SME's confidence in their evaluation.\n",
        "\n",
        "**Preserve Modified Pairs:** Save the modified question-answer-citation pairs for potential use as few-shot examples in future model fine-tuning.\n",
        "\n",
        "**Remember:**\n",
        "\n",
        "*   The manual review process is crucial for ensuring the quality and reliability of the RAG system's outputs.\n",
        "*   By incorporating diverse SME perspectives and implementing robust review strategies, you can enhance the accuracy, fairness, and overall effectiveness of your LLM-powered RAG system.\n",
        "\n",
        "**Please note:** This markdown serves as a raw template. You may need to further customize it to align with your specific project requirements and internal workflows.\n",
        "\n",
        "Let me know if you have any further questions or would like assistance refining this process!"
      ],
      "metadata": {
        "id": "Tp7eySYPJpeN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Manual Review Process for Multimodal RAG Question-Answer-Citation Pairs\n",
        "\n",
        "**SME Review (1-5 SMEs)**\n",
        "\n",
        "| Review Aspect | Voting Criteria | Description |\n",
        "|---|---|---|\n",
        "| **Answer Quality** | Accurate (1/0) | Is the answer factually correct and pertinent to the question? |\n",
        "|  | Comprehensive (1/0) | Does the answer fully address all aspects of the query? |\n",
        "|  | Well-written (1/0) | Is the answer clear, concise, and grammatically sound? |\n",
        "| **Question Clarity** | Clear (1/0) | Is the question unambiguous and easy to understand? |\n",
        "|  | Relevant (1/0) | Does the question pertain to the given context or topic? |\n",
        "|  | Concise (1/0) | Is the question formulated in a brief and to-the-point manner? |\n",
        "| **Citation Validity** | Authentic (1/0) | Is the citation from a reputable and trustworthy source? |\n",
        "|  | Relevant (1/0) | Does the citation directly support the provided answer? |\n",
        "|  | Accessible (1/0) | Can the citation be easily located and verified? |\n",
        "| **Question Type Alignment** | Accurate (1/0) | Does the assigned 'question_type' correctly reflect the nature of the question? |\n",
        "| **Compliance & Policy Adherence** | Compliant (1/0) | Does the pair adhere to internal guidelines and policies? |\n",
        "|  | Sensitive Content (1/0) | Does the pair contain any potentially offensive or harmful material? |\n",
        "|  | Bias (1/0) | Does the pair exhibit any form of prejudice or discrimination? |\n",
        "| **Strategies & Policies Adherence** | Adheres to Strategies (1/0) | Is the pair aligned with the predefined data generation strategies? |\n",
        "|  | Adheres to Policies (1/0) | Does the pair comply with the established data generation policies? |\n",
        "| **Additional Voting** | Drop (1/0) | Should the pair be removed from the dataset entirely? |\n",
        "|  | Modify (1/0) | Does the pair require adjustments or corrections? |\n",
        "|  | Correct Citation (1/0) | Is the citation inaccurate or in need of revision? |\n",
        "|  | Confidence (1-5) | How confident is the SME in their overall evaluation of the pair? |\n",
        "\n",
        "**Preserve Modified Pairs:** Save the modified question-answer-citation pairs for potential use as few-shot examples in future model fine-tuning.\n",
        "\n",
        "**Remember:**\n",
        "\n",
        "*   The manual review process is crucial for ensuring the quality and reliability of the RAG system's outputs.\n",
        "*   By incorporating diverse SME perspectives and implementing robust review strategies, you can enhance the accuracy, fairness, and overall effectiveness of your LLM-powered RAG system."
      ],
      "metadata": {
        "id": "IF8iCz50Jqhx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Generation"
      ],
      "metadata": {
        "id": "umgp-ykxJw2D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Defining Variables\n",
        "\n",
        "question_types_dict = {\n",
        "    \"Factual Extraction Questions\": {\n",
        "        \"Description\": \"Seek specific information or facts directly from retrieved multimodal data.\",\n",
        "        \"Complexity\": \"Low to Moderate\",\n",
        "        \"Reasoning\": \"Minimal to Basic\",\n",
        "        \"Examples\": [\n",
        "            \"What was the company's net income in Q2 2023? (from financial report)\",\n",
        "            \"Identify the key trends in the company's stock price over the past year. (from financial graph)\",\n",
        "            \"Who is the CEO of the company? (from launch video or earnings call audio)\"\n",
        "        ]\n",
        "    },\n",
        "    \"Synthesis Questions\": {\n",
        "        \"Description\": \"Require combining information from multiple parts or modalities of retrieved data.\",\n",
        "        \"Complexity\": \"Moderate\",\n",
        "        \"Reasoning\": \"Integration of information from various sources.\",\n",
        "        \"Examples\": [\n",
        "            \"Summarize the company's financial performance for the fiscal year based on the annual report and earnings call transcript.\",\n",
        "            \"What are the key features of the new product as highlighted in the launch video and discussed in the earnings call?\"\n",
        "        ]\n",
        "    },\n",
        "    \"Inferential Questions\": {\n",
        "        \"Description\": \"Require going beyond explicit information and making deductions or drawing conclusions from multimodal data.\",\n",
        "        \"Complexity\": \"High\",\n",
        "        \"Reasoning\": \"Logical reasoning, potentially involving cross-modal inference and application of financial knowledge.\",\n",
        "        \"Examples\": [\n",
        "            \"Based on the CEO's tone in the earnings call and the company's financial performance in the recent quarter, what are the potential challenges the company might be facing?\",\n",
        "            \"What is the company's strategic focus for the next year based on the product roadmap presented in the launch video and the discussions in the earnings call?\"\n",
        "        ]\n",
        "    },\n",
        "    \"Multi-hop Reasoning Questions\": {\n",
        "        \"Description\": \"Involve chaining multiple facts or evidence across modalities to arrive at an answer.\",\n",
        "        \"Complexity\": \"Very High\",\n",
        "        \"Reasoning\": \"Complex reasoning across different data types, potentially involving causal or temporal relationships.\",\n",
        "        \"Examples\": [\n",
        "            \"How did the new product launch, as detailed in the launch video, impact the company's revenue in the subsequent quarter, as reported in the financial statements?\",\n",
        "            \"Identify any inconsistencies between the financial projections mentioned in the earnings call and the actual results presented in the quarterly report.\"\n",
        "        ]\n",
        "    },\n",
        "    \"Comparative Questions\": {\n",
        "        \"Description\": \"Explicitly ask for comparisons between entities, events, or concepts across modalities.\",\n",
        "        \"Complexity\": \"Moderate\",\n",
        "        \"Reasoning\": \"Identification and comparison of relevant attributes across different data types.\",\n",
        "        \"Examples\": [\n",
        "            \"Compare the company's revenue growth in the past two quarters as shown in the financial charts.\",\n",
        "            \"How do the features of the newly launched product, as shown in the video, compare to those of the previous generation product mentioned in the last year's annual report?\"\n",
        "        ]\n",
        "    },\n",
        "    \"Temporal Questions\": {\n",
        "        \"Description\": \"Involve understanding the timeline of events or changes in states across multimodal data.\",\n",
        "        \"Complexity\": \"Moderate\",\n",
        "        \"Reasoning\": \"Extraction and alignment of temporal information from various sources.\",\n",
        "        \"Examples\": [\n",
        "            \"Trace the evolution of the company's product line over the past five years based on launch videos and annual reports.\",\n",
        "            \"How has the company's profit margin changed over the last three fiscal years as shown in the financial statements?\"\n",
        "        ]\n",
        "    },\n",
        "    \"Hypothetical Questions\": {\n",
        "        \"Description\": \"Ask about potential outcomes or scenarios based on multimodal data.\",\n",
        "        \"Complexity\": \"High\",\n",
        "        \"Reasoning\": \"Combines information from various modalities with financial knowledge and makes predictions or inferences.\",\n",
        "        \"Examples\": [\n",
        "            \"If the company were to expand into a new market, as hinted at in the earnings call, what potential impact could it have on its revenue?\",\n",
        "            \"What could be the potential challenges if the company decides to discontinue one of its product lines, based on the information in the latest earnings call and product launch videos?\"\n",
        "        ]\n",
        "    },\n",
        "    \"Open-Ended Questions\": {\n",
        "        \"Description\": \"Do not have a single correct answer, invite opinions, discussions, or creative responses based on multimodal data.\",\n",
        "        \"Complexity\": \"High\",\n",
        "        \"Reasoning\": \"Involves synthesis, inference, and potentially generation of novel ideas, drawing from various modalities.\",\n",
        "        \"Examples\": [\n",
        "            \"What are the key strengths and weaknesses of the company's current business strategy based on all available information?\",\n",
        "            \"Discuss the potential risks and opportunities associated with investing in this company.\"\n",
        "        ]\n",
        "    },\n",
        "    \"Code Generation/Debugging Questions (Financial Context)\": {\n",
        "        \"Description\": \"Target understanding and generation of code or identification of errors, specifically related to financial analysis or modeling.\",\n",
        "        \"Complexity\": \"High\",\n",
        "        \"Reasoning\": \"Combines information retrieval from various modalities with logical reasoning about financial code and data.\",\n",
        "        \"Examples\": [\n",
        "            \"Write a Python script to visualize the company's quarterly revenue trend over the past two years using the data from the financial reports.\",\n",
        "            \"Identify any potential errors in the calculation of the company's debt-to-equity ratio in the provided financial spreadsheet.\"\n",
        "        ]\n",
        "    },\n",
        "    \"Ambiguous Questions\": {\n",
        "        \"Description\": \"Can have multiple interpretations or require clarification, especially when dealing with multimodal data.\",\n",
        "        \"Complexity\": \"High\",\n",
        "        \"Reasoning\": \"Identifying ambiguities across different modalities, seeking clarification, or providing multiple interpretations.\",\n",
        "        \"Examples\": [\n",
        "            \"Tell me about the company's performance. (Ambiguous - could refer to financial, operational, or other aspects)\",\n",
        "            \"What is the outlook? (Ambiguous - could be financial outlook, product outlook, or market outlook)\"\n",
        "        ]\n",
        "    },\n",
        "    \"Contextual Questions\": {\n",
        "        \"Description\": \"Rely on understanding the broader context of a conversation or series of interactions, considering multimodal data.\",\n",
        "        \"Complexity\": \"High\",\n",
        "        \"Reasoning\": \"Tracking previous queries and responses across modalities, identifying entities and their relationships.\",\n",
        "        \"Examples\": [\n",
        "            \"Can you show me a graph illustrating that trend? (Contextual - assumes a previous mention of a specific trend)\",\n",
        "            \"Explain the impact of that event on the company's stock price. (Contextual - refers to a previously discussed event)\"\n",
        "        ]\n",
        "    },\n",
        "    \"Subjective Questions\": {\n",
        "        \"Description\": \"Ask for opinions, preferences, or value judgments based on multimodal data, potentially requiring nuanced understanding of financial implications.\",\n",
        "        \"Complexity\": \"High\",\n",
        "        \"Reasoning\": \"Identifying diverse perspectives across modalities, acknowledging subjectivity, and potentially offering a balanced or personalized response.\",\n",
        "        \"Examples\": [\n",
        "            \"Is the company's current CEO doing a good job?\",\n",
        "            \"Should the company consider diversifying its product portfolio?\"\n",
        "        ]\n",
        "    },\n",
        "    \"Creative Questions\": {\n",
        "        \"Description\": \"Call for imaginative or innovative responses based on multimodal data, potentially involving financial storytelling or idea generation.\",\n",
        "        \"Complexity\": \"Very High\",\n",
        "        \"Reasoning\": \"Combining information from various modalities with creative thinking, generating novel connections, or producing original content related to finance.\",\n",
        "        \"Examples\": [\n",
        "            \"Create a compelling narrative highlighting the company's key achievements and milestones over the years, drawing from launch videos and annual reports.\",\n",
        "            \"Propose a new marketing campaign for the recently launched product, incorporating insights from the launch video and target audience analysis in the market research report.\"\n",
        "        ]\n",
        "    },\n",
        "    \"Domain-Specific Questions (Finance)\": {\n",
        "        \"Description\": \"Pertain to specialized areas within finance, requiring in-depth knowledge and understanding of specific terminology and concepts across modalities.\",\n",
        "        \"Complexity\": \"Varies\",\n",
        "        \"Reasoning\": \"Necessitates access to relevant financial documents, potentially specialized language models, and understanding of financial jargon across text, audio, and visual data.\",\n",
        "        \"Examples\": [\n",
        "            \"Explain the concept of 'discounted cash flow' and how it's used in valuing the company.\",\n",
        "            \"Analyze the company's risk exposure based on the information in the financial statements and risk factors discussed in the earnings call.\"\n",
        "        ]\n",
        "    },\n",
        "    \"Counterfactual Questions\": {\n",
        "        \"Description\": \"Explore 'what if' scenarios by altering past facts or events.\",\n",
        "        \"Complexity\": \"Very High\",\n",
        "        \"Reasoning\": \"Understanding cause-and-effect, simulating alternative realities, predicting outcomes.\",\n",
        "        \"Example\": [\n",
        "            \"How would the company's stock price have been affected if they had not acquired that competitor last year, based on the market conditions at that time?\"\n",
        "        ]\n",
        "    },\n",
        "    \"Ethical/Moral Questions\": {\n",
        "        \"Description\": \"Delve into the ethical or moral implications of a company's actions or decisions.\",\n",
        "        \"Complexity\": \"High\",\n",
        "        \"Reasoning\": \"Understanding ethical frameworks, societal norms, and potentially generating nuanced arguments.\",\n",
        "        \"Example\": [\n",
        "            \"Was the company's decision to lay off a significant portion of its workforce during the economic downturn morally justifiable?\"\n",
        "        ]\n",
        "    },\n",
        "    \"Causal Questions\": {\n",
        "        \"Description\": \"Seek to identify cause-and-effect relationships between events or factors.\",\n",
        "        \"Complexity\": \"High\",\n",
        "        \"Reasoning\": \"Disentangling complex relationships, considering multiple variables, identifying confounding factors.\",\n",
        "        \"Example\": [\n",
        "            \"What were the key factors that contributed to the company's significant increase in market share over the past two years?\"\n",
        "        ]\n",
        "    },\n",
        "    \"Prediction Questions\": {\n",
        "        \"Description\": \"Ask for forecasts or predictions about future events or trends.\",\n",
        "        \"Complexity\": \"High\",\n",
        "        \"Reasoning\": \"Identifying patterns, trends, and potentially utilizing predictive modeling.\",\n",
        "        \"Example\": [\n",
        "            \"Based on the company's current financial performance and market trends, what is the likely outlook for its stock price in the next six months?\"\n",
        "        ]\n",
        "    },\n",
        "    \"Anomaly Detection Questions\": {\n",
        "        \"Description\": \"Aim to identify unusual or unexpected patterns or data points.\",\n",
        "        \"Complexity\": \"High\",\n",
        "        \"Reasoning\": \"Understanding normal patterns and deviations, potentially involving statistical analysis.\",\n",
        "        \"Example\": [\n",
        "            \"Are there any unusual fluctuations in the company's cash flow statement that warrant further investigation?\"\n",
        "        ]\n",
        "    }\n",
        "}\n",
        "\n",
        "#follows OpenAPI 3.0\n",
        "response_schema_gemini_pro = {\n",
        "  \"type\": \"object\",\n",
        "  \"properties\": {\n",
        "    \"question\": {\n",
        "      \"type\": \"string\",\n",
        "      \"description\": \"The question posed to the files.\"\n",
        "    },\n",
        "    \"answer\": {\n",
        "      \"type\": \"string\",\n",
        "      \"description\": \"The generated answer to the question.\"\n",
        "    },\n",
        "    \"text_citation\": {\n",
        "      \"type\": \"array\",\n",
        "      \"items\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "          \"file_name\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"Name of the PDF file.\"\n",
        "          },\n",
        "          \"page_number\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"Page number in the PDF file.\"\n",
        "          },\n",
        "          \"text\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"Exact text from the PDF file.\"\n",
        "          }\n",
        "        },\n",
        "        \"required\": [\"file_name\", \"page_number\", \"text\"]\n",
        "      },\n",
        "      \"description\": \"List of text citations from PDF files.\"\n",
        "    },\n",
        "    \"audio_citation\": {\n",
        "      \"type\": \"array\",\n",
        "      \"items\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "          \"file_name\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"Name of the MP3 file.\"\n",
        "          },\n",
        "          \"timestamp_range\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"Timestamp range in the MP3 file.\"\n",
        "          },\n",
        "          \"transcript\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"Exact excerpt of transcript from the MP3 file.\"\n",
        "          }\n",
        "        },\n",
        "        \"required\": [\"file_name\", \"timestamp_range\", \"transcript\"]\n",
        "      },\n",
        "      \"description\": \"List of audio citations from MP3 files.\"\n",
        "    },\n",
        "    \"video_citation\": {\n",
        "      \"type\": \"array\",\n",
        "      \"items\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "          \"file_name\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"Name of the MP4 file.\"\n",
        "          },\n",
        "          \"timestamp_range\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"Timestamp range in the MP4 file.\"\n",
        "          },\n",
        "          \"transcript\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"Exact excerpt of transcript from the MP4 file.\"\n",
        "          }\n",
        "        },\n",
        "        \"required\": [\"file_name\", \"timestamp_range\", \"transcript\"]\n",
        "      },\n",
        "      \"description\": \"List of video citations from MP4 files.\"\n",
        "    }\n",
        "  },\n",
        "  \"required\": [\"question\", \"answer\", \"text_citation\", \"audio_citation\", \"video_citation\"]\n",
        "}\n",
        "\n",
        "response_schema_gemini_flash = \"\"\"{{\n",
        "\"question\": \"generated question\",\n",
        "\"answer\": \"generate answer\",\n",
        "\"text_citation\":  [if pdf: list of all text citations. mention all the file name, page_number and exact text in dictionary.]\n",
        "\"audio_citation\": [if mp3: list of all audio citations. mention all the file name, timestamp and exact excerpt of transcript in dictionary.]\n",
        "\"video_citation\": [if mp4: list of all video citations. mention all the file name, timestamp and exact excerpt of transcript in dictionary.]\n",
        "}}\n",
        "\"\"\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "YN5jDbZTyGAF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Defining Prompts\n",
        "\n",
        "# prompt\n",
        "\n",
        "# Fusion Generation Prompt\n",
        "\n",
        "fushion_generation_task_prompt = \"\"\"Task: I need you to generate questions where the answers require synthesizing information across multiple files (PDF, video, and audio). The answer should NOT be found within a single file; it should combine insights from at least two different file types.\n",
        "Example to follow:\n",
        "\n",
        "Consider the following files:\n",
        "* \"Climate Change Impacts\" (PDF)\n",
        "* \"Renewable Energy Solutions\" (Video)\n",
        "* \"Expert Panel on Sustainability\" (Audio)\n",
        "\n",
        "Pay attention to how the concept of 'sustainability' is discussed in both the video and the audio file.\n",
        "\n",
        "Do not generate questions that can be answered with a simple fact or definition. The ideal question should require analysis, comparison, or evaluation across different sources.\n",
        "\n",
        "Generate a questions that meet these criteria.\n",
        "\n",
        "Follow the context and guidlines below:\n",
        "\"\"\"\n",
        "\n",
        "normal_generation_task_prompt = \"\"\"Task: Generate a question, its relevant context, and the corresponding answer based on the provided multimodal data.\n",
        "    Follow the context and guidlines below:\n",
        "    \"\"\"\n",
        "\n",
        "# Guidelines Prompt\n",
        "guidelines_prompt = \"\"\"Guidelines:\n",
        "\n",
        "Question:\n",
        "- Formulate a clear, focused question directly targeting specific information or facts evident in the data.\n",
        "- Ensure alignment with the specified question type and its intended complexity level.\n",
        "- Avoid ambiguous or overly broad questions.\n",
        "- Do not mention \"in this video/audio/pdf\" or anything that reference the filenames in the question.\n",
        "- If the question is based on video, audio, then don't mention \"speaker\" or reference the file.\n",
        "- If the question is something related to time based entity, mention the time values like year, quarters, months, day etc.\n",
        "\n",
        "Answer:\n",
        "- Provide a concise, accurate answer directly addressing the question.\n",
        "- Ensure the answer is fully supported by the context.\n",
        "- If reasoning/inference is involved: demonstrate the logical steps.\n",
        "- If insufficient information: state \"Answer not found in the provided data\" .\n",
        "\n",
        "Citations:\n",
        "- Provide accurate, complete citations including source titles and identifiers (page numbers, timestamps).\n",
        "- Cite multiple sources if applicable.\n",
        "- Follow the Output Format.\n",
        "\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ec5Sb-S_zDCn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Data Generation Helper Functions\n",
        "\n",
        "\n",
        "def generate_questions_and_responses(total_run=1, total_ques_per_run=1,\n",
        "                                     question_types=None, model=\"pro\", fusion_generation=False,\n",
        "                                     gs_path_list=None, response_schema=None):\n",
        "    \"\"\"\n",
        "    Generates questions and responses based on provided parameters.\n",
        "\n",
        "    Args:\n",
        "        total_run (int): The number of outer loops to run.\n",
        "        total_ques_per_run (int): The number of questions to generate per run.\n",
        "        question_types (list): A list of question types to choose from. If None, all types will be used.\n",
        "        model (str): The model to use for generating responses (\"pro\" or \"flash\").\n",
        "        fusion_generation (bool): Whether to use fusion generation.\n",
        "        gs_path_list (list): A list of GCS paths to select files from.\n",
        "        response_schema (dict): The response schema to use.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of generated responses.\n",
        "    \"\"\"\n",
        "\n",
        "    final_data = []\n",
        "\n",
        "    if question_types is None:\n",
        "        question_types = ['Factual Extraction Questions', 'Synthesis Questions', 'Inferential Questions',\n",
        "                          'Multi-hop Reasoning Questions', 'Comparative Questions', 'Temporal Questions',\n",
        "                          'Ethical/Moral Questions', 'Prediction Questions', 'Anomaly Detection Questions']\n",
        "\n",
        "    for outer_logic in range(total_run):\n",
        "        print(\"running count: \",outer_logic+1)\n",
        "        question_type = random.choice(question_types)\n",
        "        print(\"question_type\", question_type)\n",
        "        question_type_description = question_types_dict[question_type]\n",
        "        selected_paths = select_random_gcs_paths_with_mime_types(gs_path_list, (1, total_ques_per_run))\n",
        "        print(\"Selected Files: \", selected_paths)\n",
        "\n",
        "        for inner_logic in range(total_ques_per_run):\n",
        "            try:\n",
        "                response = get_gemini_response_json(\n",
        "                    question_type,\n",
        "                    question_type_description,\n",
        "                    model=model,\n",
        "                    response_schema=response_schema,\n",
        "                    fusion_generation=fusion_generation,\n",
        "                    file_configs=selected_paths\n",
        "                )\n",
        "                response['file_type'] = [each['gcs_path'].split(\".\")[-1] for each in selected_paths]\n",
        "                final_data.append(response)\n",
        "            except Exception as e:\n",
        "                print(\"Error occurred. Skipping. Error: \", e)\n",
        "                continue\n",
        "\n",
        "    return final_data\n",
        "\n",
        "def get_blob_uri(bucket_name: str, blob_name: str) -> str:\n",
        "    \"\"\"Gets the full URI of the blob in Google Cloud Storage.\n",
        "\n",
        "    Args:\n",
        "        bucket_name: The name of the GCS bucket.\n",
        "        blob_name: The name of the blob within the bucket.\n",
        "\n",
        "    Returns:\n",
        "        The full GCS URI (gs://...) of the blob.\n",
        "    \"\"\"\n",
        "    return f\"gs://{bucket_name}/{blob_name}\"\n",
        "\n",
        "\n",
        "def get_gs_paths_for_production_media(bucket: Bucket, production_data: str) -> List[str]:\n",
        "  \"\"\"\n",
        "  Retrieves Google Storage URIs for media files (PDF, MP4, MP3)\n",
        "  within a specified production data prefix.\n",
        "\n",
        "  Args:\n",
        "      bucket: The Google Cloud Storage bucket to search.\n",
        "      production_data: The prefix indicating production data.\n",
        "\n",
        "  Returns:\n",
        "      A list of Google Storage URIs for the matching media files.\n",
        "  \"\"\"\n",
        "\n",
        "  gs_path_list = []\n",
        "  for blob in bucket.list_blobs():\n",
        "    if blob.name.startswith(production_data) and (\n",
        "        blob.name.endswith(\".pdf\") or\n",
        "        blob.name.endswith(\".mp4\") or\n",
        "        blob.name.endswith(\".mp3\")\n",
        "    ):\n",
        "      gs_path_list.append(get_blob_uri(bucket.name, blob.name))\n",
        "\n",
        "  return gs_path_list\n",
        "\n",
        "def select_random_gcs_paths_with_mime_types(gcs_path_list, selection_range):\n",
        "    \"\"\"\n",
        "    Randomly selects GCS paths and returns them with their corresponding MIME types.\n",
        "\n",
        "    Args:\n",
        "        gcs_path_list: A list of GCS paths to choose from.\n",
        "        selection_range: A tuple (min_files, max_files) specifying the\n",
        "                         minimum and maximum number of files to select.\n",
        "\n",
        "    Returns:\n",
        "        A list of dictionaries, each containing a \"gcs_path\" and its \"mime_type\".\n",
        "    \"\"\"\n",
        "\n",
        "    min_files, max_files = selection_range\n",
        "    num_files_to_select = random.randint(min_files, max_files)\n",
        "    selected_paths = random.sample(gcs_path_list, num_files_to_select)\n",
        "\n",
        "    # Map file extensions to MIME types\n",
        "    extension_mime_type_mapping = {\n",
        "        'pdf': 'application/pdf',\n",
        "        'mp3': 'audio/mpeg',\n",
        "        'mp4': 'video/mp4'\n",
        "    }\n",
        "\n",
        "    # Create the final result list\n",
        "    result = []\n",
        "    for path in selected_paths:\n",
        "        _, file_extension = os.path.splitext(path)\n",
        "        file_extension = file_extension[1:].lower()  # Remove the dot and convert to lowercase\n",
        "\n",
        "        mime_type = extension_mime_type_mapping.get(file_extension, 'application/octet-stream')\n",
        "        # Default to 'application/octet-stream' for unknown extensions\n",
        "\n",
        "        result.append({\"gcs_path\": path, \"mime_type\": mime_type})\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "import random\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_gemini_response_json(question_type, question_type_description,\n",
        "                             model=\"flash\", response_schema=None,\n",
        "                             fusion_generation=False,\n",
        "                             file_configs=[]):\n",
        "  # control generation for JSON using Gemini Flash\n",
        "  if fusion_generation:\n",
        "    print(\"Fusion Generation\")\n",
        "    instruction = fushion_generation_task_prompt\n",
        "  else:\n",
        "    print(\"Normal Generation\")\n",
        "    instruction = normal_generation_task_prompt\n",
        "\n",
        "  question_context_answer_prompt = f\"\"\"{instruction}\n",
        "\n",
        "Question Type: {question_type}\n",
        "\n",
        "Question Type Description: {question_type_description}\n",
        "\n",
        "File Sources: {file_configs}\n",
        "\n",
        "{guidelines_prompt}\n",
        "\n",
        "{\"Output Format: \"+response_schema_gemini_flash if model=='flash' else \"\"}\n",
        "\"\"\"\n",
        "\n",
        "  if model == \"pro\":\n",
        "    print(\"Using Gemini 1.5 Pro model for Data Generation with provided OpenAPI schema\")\n",
        "    cg_model = GenerativeModel(\n",
        "        model_name=\"gemini-1.5-pro\",\n",
        "      generation_config=GenerationConfig(\n",
        "          response_mime_type=\"application/json\", response_schema=response_schema\n",
        "      ),\n",
        "    )\n",
        "  elif model == \"flash\":\n",
        "    print(\"Using Gemini 1.5 Flash model for Data Generation with provided schema in prompt\")\n",
        "    cg_model = GenerativeModel(\n",
        "      model_name=\"gemini-1.5-flash\",\n",
        "      generation_config={\"response_mime_type\": \"application/json\"},\n",
        "      # generation_config=generation_config,\n",
        "  )\n",
        "\n",
        "\n",
        "\n",
        "  # Dynamically create Part objects based on file configurations\n",
        "  content = [question_context_answer_prompt]\n",
        "  content.extend([Part.from_uri(config['gcs_path'], mime_type=config['mime_type']) for config in file_configs])\n",
        "\n",
        "  # Add the analysis prompt\n",
        "  # print(question_context_answer_prompt)\n",
        "  content.append(question_context_answer_prompt)\n",
        "\n",
        "  response = cg_model.generate_content(content)\n",
        "\n",
        "  json_response = json.loads(response.text)\n",
        "\n",
        "  json_response[\"source_file\"] = [config['gcs_path'] for config in file_configs]\n",
        "  json_response[\"question_type\"] = question_type\n",
        "  json_response[\"question_type_description\"] = question_type_description['Complexity']\n",
        "\n",
        "  return (json_response)\n",
        "\n",
        "def generate_questions_and_responses(total_run=1, total_ques_per_run=1,\n",
        "                                     min_file_select=1, max_file_select=2,\n",
        "                                     question_types=None, model=\"pro\", fusion_generation=False,\n",
        "                                     gs_path_list=None, response_schema=None,\n",
        "                                     output_format=None, output_path=None):\n",
        "\n",
        "    \"\"\"\n",
        "    Generates questions and responses based on provided parameters.\n",
        "\n",
        "    Args:\n",
        "        total_run (int): The number of outer loops to run.\n",
        "        total_ques_per_run (int): The number of questions to generate per run.\n",
        "        question_types (list): A list of question types to choose from. If None, all types will be used.\n",
        "        model (str): The model to use for generating responses (\"pro\" or \"flash\").\n",
        "        fusion_generation (bool): Whether to use fusion generation.\n",
        "        gs_path_list (list): A list of GCS paths to select files from.\n",
        "        response_schema (dict): The response schema to use.\n",
        "        output_format (str): The desired output format (\"return_df\" or \"output_path\").\n",
        "        output_path (str): The path to save the DataFrame if output_format is \"output_path\".\n",
        "\n",
        "\n",
        "    Returns:\n",
        "        list: A list of generated responses.\n",
        "        pd.DataFrame or None: A DataFrame if output_format is \"return_df\", otherwise None.\n",
        "    \"\"\"\n",
        "\n",
        "    final_data = []\n",
        "\n",
        "    if question_types is None:\n",
        "        question_types = ['Factual Extraction Questions', 'Synthesis Questions', 'Inferential Questions',\n",
        "                          'Multi-hop Reasoning Questions', 'Comparative Questions', 'Temporal Questions',\n",
        "                          'Ethical/Moral Questions', 'Prediction Questions', 'Anomaly Detection Questions']\n",
        "\n",
        "    for outer_logic in range(total_run):\n",
        "        print(\"running count: \",outer_logic+1)\n",
        "        question_type = random.choice(question_types)\n",
        "        print(\"question_type\", question_type)\n",
        "        question_type_description = question_types_dict[question_type]\n",
        "        selected_paths = select_random_gcs_paths_with_mime_types(gs_path_list, (min_file_select,\n",
        "                                                                                max_file_select))\n",
        "        print(\"Selected Files: \", selected_paths)\n",
        "\n",
        "        for inner_logic in range(total_ques_per_run):\n",
        "            try:\n",
        "                response = get_gemini_response_json(\n",
        "                    question_type,\n",
        "                    question_type_description,\n",
        "                    model=model,\n",
        "                    response_schema=response_schema,\n",
        "                    fusion_generation=fusion_generation,\n",
        "                    file_configs=selected_paths\n",
        "                )\n",
        "                response['file_type'] = [each['gcs_path'].split(\".\")[-1] for each in selected_paths]\n",
        "                final_data.append(response)\n",
        "            except Exception as e:\n",
        "                print(\"Error occurred. Skipping. Error: \", e)\n",
        "                continue\n",
        "\n",
        "    if output_format == \"return_df\":\n",
        "        return pd.DataFrame(final_data)\n",
        "    elif output_format == \"save_df\":\n",
        "        print(\"saving the final datafram at: \", output_path)\n",
        "        pd.DataFrame(final_data).to_csv(output_path, index=False)\n",
        "    else:\n",
        "        return final_data  # Default behavior if no output_format is specified"
      ],
      "metadata": {
        "cellView": "form",
        "id": "GXMduitYx8xl"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gs_path_list = get_gs_paths_for_production_media(bucket, production_data)"
      ],
      "metadata": {
        "id": "eLB9NuN85n79"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Gemin 1.5 Pro to generate a single question-answer pair with random question-category\n",
        "# selecting atleast 2 or 3 files at a time for all question types\n",
        "# keeping fusion_generation=True, since question generation should fuse the files.\n",
        "\n",
        "pro_results_2_3 = generate_questions_and_responses(\n",
        "    total_run=2,\n",
        "    total_ques_per_run=1,\n",
        "    min_file_select = 2,\n",
        "    max_file_select = 3,\n",
        "    model=\"pro\",\n",
        "    fusion_generation=True,  # Enable fusion generation\n",
        "    gs_path_list=gs_path_list,\n",
        "    response_schema=response_schema_gemini_pro,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2UHmMgf5Ngq",
        "outputId": "915f3505-a6aa-46fe-8b8a-9c0b0fb88833"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running count:  1\n",
            "question_type Temporal Questions\n",
            "Selected Files:  [{'gcs_path': 'gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/reports/2020/quaterly_report/20200429-alphabet-10q.pdf', 'mime_type': 'application/pdf'}, {'gcs_path': 'gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/podcast/episode2.mp3', 'mime_type': 'audio/mpeg'}, {'gcs_path': 'gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/earning_call/Alphabet 2023 Q3 Earnings Call (128 kbps).mp3', 'mime_type': 'audio/mpeg'}]\n",
            "Fusion Generation\n",
            "Using Gemini 1.5 Pro model for Data Generation with provided OpenAPI schema\n",
            "running count:  2\n",
            "question_type Synthesis Questions\n",
            "Selected Files:  [{'gcs_path': 'gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/earning_call/Alphabet_2023_Q1_Earnings_Call.mp3', 'mime_type': 'audio/mpeg'}, {'gcs_path': 'gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/reports/2022/annual_report/2022-alphabet-annual-report.pdf', 'mime_type': 'application/pdf'}, {'gcs_path': 'gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/podcast/episode6.mp3', 'mime_type': 'audio/mpeg'}]\n",
            "Fusion Generation\n",
            "Using Gemini 1.5 Pro model for Data Generation with provided OpenAPI schema\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Gemin 1.5 Pro to generate a single question-answer pair with random question-category\n",
        "# selecting atleast 2 or 3 files at a time for all question types\n",
        "# keeping fusion_generation=True, since question generation should fuse the files.\n",
        "# returning dataframe rather than dataframe\n",
        "\n",
        "pro_results_2_3_df = generate_questions_and_responses(\n",
        "    total_run=1,\n",
        "    total_ques_per_run=1,\n",
        "    min_file_select = 1,\n",
        "    max_file_select = 1,\n",
        "    model=\"pro\",\n",
        "    # fusion_generation=True,  # Enable fusion generation\n",
        "    gs_path_list=gs_path_list,\n",
        "    response_schema=response_schema_gemini_pro,\n",
        "    output_format='return_df',\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uh2dAX7CD09",
        "outputId": "dbdee03e-4dbb-4f45-ba09-c2ad9adb9f8f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running count:  1\n",
            "question_type Factual Extraction Questions\n",
            "Selected Files:  [{'gcs_path': 'gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/product_launch/gemini/Guessing movies with AI  Testing Gemini.mp4', 'mime_type': 'video/mp4'}]\n",
            "Normal Generation\n",
            "Using Gemini 1.5 Pro model for Data Generation with provided OpenAPI schema\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pro_results_2_3_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "ctIjHh8rCogB",
        "outputId": "44b332ae-da5c-4d50-b590-fc7dbb5bcd2b"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              answer audio_citation  \\\n",
              "0  The movie title guessed by Gemini using the im...             []   \n",
              "\n",
              "                                            question text_citation  \\\n",
              "0  What is the movie title guessed by Gemini when...            []   \n",
              "\n",
              "                                      video_citation  \\\n",
              "0  [{'file_name': 'gs://mlops-for-genai/multimoda...   \n",
              "\n",
              "                                         source_file  \\\n",
              "0  [gs://mlops-for-genai/multimodal-finanace-qa/d...   \n",
              "\n",
              "                  question_type question_type_description file_type  \n",
              "0  Factual Extraction Questions           Low to Moderate     [mp4]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7d722061-0d4b-47b5-b9b8-0b4e7044fbfb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>answer</th>\n",
              "      <th>audio_citation</th>\n",
              "      <th>question</th>\n",
              "      <th>text_citation</th>\n",
              "      <th>video_citation</th>\n",
              "      <th>source_file</th>\n",
              "      <th>question_type</th>\n",
              "      <th>question_type_description</th>\n",
              "      <th>file_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The movie title guessed by Gemini using the im...</td>\n",
              "      <td>[]</td>\n",
              "      <td>What is the movie title guessed by Gemini when...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[{'file_name': 'gs://mlops-for-genai/multimoda...</td>\n",
              "      <td>[gs://mlops-for-genai/multimodal-finanace-qa/d...</td>\n",
              "      <td>Factual Extraction Questions</td>\n",
              "      <td>Low to Moderate</td>\n",
              "      <td>[mp4]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7d722061-0d4b-47b5-b9b8-0b4e7044fbfb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7d722061-0d4b-47b5-b9b8-0b4e7044fbfb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7d722061-0d4b-47b5-b9b8-0b4e7044fbfb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "pro_results_2_3_df",
              "summary": "{\n  \"name\": \"pro_results_2_3_df\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"The movie title guessed by Gemini using the image of a breakfast plate and a ring is \\\"Breakfast at Tiffany's.\\\"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"audio_citation\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"What is the movie title guessed by Gemini when presented with a breakfast plate and a ring image?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text_citation\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"video_citation\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source_file\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question_type\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Factual Extraction Questions\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question_type_description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Low to Moderate\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"file_type\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Gemin 1.5 Pro to generate a single question-answer pair with random question-category\n",
        "# selecting atleast 2 or 3 files at a time for all question types\n",
        "# keeping fusion_generation=True, since question generation should fuse the files.\n",
        "# persisting the results in external path\n",
        "\n",
        "pro_results_2_3_csv = generate_questions_and_responses(\n",
        "    total_run=1,\n",
        "    total_ques_per_run=1,\n",
        "    min_file_select = 1,\n",
        "    max_file_select = 2,\n",
        "    model=\"pro\",\n",
        "    fusion_generation=True,  # Enable fusion generation\n",
        "    gs_path_list=gs_path_list,\n",
        "    response_schema=response_schema_gemini_pro,\n",
        "    output_format='save_df',\n",
        "    output_path='/content/run_gen_pro_1112_fushion.csv',\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Swx-QHA5CTyo",
        "outputId": "a002607c-a73b-4867-90a1-8d850630d9b9"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running count:  1\n",
            "question_type Comparative Questions\n",
            "Selected Files:  [{'gcs_path': 'gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/earning_call/Alphabet 2024 Q2 Earnings Call (128 kbps).mp3', 'mime_type': 'audio/mpeg'}]\n",
            "Fusion Generation\n",
            "Using Gemini 1.5 Pro model for Data Generation with provided OpenAPI schema\n",
            "saving the final datafram at:  /content/run_gen_pro_1112_fushion.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Gemin 1.5 Pro to generate a single question-answer pair with random question-category\n",
        "# selecting only one file for all question types\n",
        "# keeping fusion_generation=False, since single file.\n",
        "\n",
        "pro_results_1_1 = generate_questions_and_responses(\n",
        "    total_run=2,\n",
        "    total_ques_per_run=1,\n",
        "    min_file_select = 1,\n",
        "    max_file_select = 1,\n",
        "    model=\"pro\",\n",
        "    gs_path_list=gs_path_list,\n",
        "    response_schema=response_schema_gemini_pro\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AoOPzVj-aG-",
        "outputId": "98991075-6ad4-4093-b352-352b17bf713e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running count:  1\n",
            "question_type Inferential Questions\n",
            "Selected Files:  [{'gcs_path': 'gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/product_launch/gemini/Guessing movies with AI  Testing Gemini.mp4', 'mime_type': 'video/mp4'}]\n",
            "Normal Generation\n",
            "Using Gemini 1.5 Pro model for Data Generation with provided OpenAPI schema\n",
            "running count:  2\n",
            "question_type Synthesis Questions\n",
            "Selected Files:  [{'gcs_path': 'gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/earning_call/Alphabet_2023_Q1_Earnings_Call.mp3', 'mime_type': 'audio/mpeg'}]\n",
            "Normal Generation\n",
            "Using Gemini 1.5 Pro model for Data Generation with provided OpenAPI schema\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Gemin 1.5 Flash to generate a single question-answer pair with random question-category\n",
        "# Flash doesn't expect response_schema\n",
        "\n",
        "results_flash_1_1_sysnques = generate_questions_and_responses(\n",
        "    total_run=1,\n",
        "    total_ques_per_run=1,\n",
        "    min_file_select = 1,\n",
        "    max_file_select = 1,\n",
        "    question_types=['Synthesis Questions'],\n",
        "    model=\"flash\",\n",
        "    # fusion_generation=True,  # Enable fusion generation\n",
        "    gs_path_list=gs_path_list\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZ2FfNuc5OoZ",
        "outputId": "3da141d2-b469-484b-b5c4-e6d598746b6a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running count:  1\n",
            "question_type Synthesis Questions\n",
            "Selected Files:  [{'gcs_path': 'gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/podcast/episode4.mp3', 'mime_type': 'audio/mpeg'}]\n",
            "Normal Generation\n",
            "Using Gemini 1.5 Flash model for Data Generation with provided schema in prompt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Combination"
      ],
      "metadata": {
        "id": "qdRnmg3wrc3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have all the list\n",
        "\n",
        "combined_list = pro_results_2_3 + pro_results_1_1 + results_flash_1_1_sysnques\n",
        "combined_df = pd.DataFrame(combined_list)"
      ],
      "metadata": {
        "id": "ECEgFnmn_Vz0"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "DwvPtloGAASI",
        "outputId": "99c6278b-da6c-400c-ae05-d1501fed0c5f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              answer audio_citation  \\\n",
              "0  Gemini is able to understand and explain the v...             []   \n",
              "1  The company saw a notable decrease in Sales & ...             []   \n",
              "\n",
              "                                            question  \\\n",
              "0  What is Gemini able to do with images created ...   \n",
              "1  Was there an unusual shift in the allocation o...   \n",
              "\n",
              "                                       text_citation  \\\n",
              "0                                                 []   \n",
              "1  [{'file_name': '2021_Q1_Earnings_Transcript.pd...   \n",
              "\n",
              "                                      video_citation  \\\n",
              "0  [{'file_name': 'Can AI understand new emojis  ...   \n",
              "1                                                 []   \n",
              "\n",
              "                                         source_file  \\\n",
              "0  [gs://mlops-for-genai/multimodal-finanace-qa/d...   \n",
              "1  [gs://mlops-for-genai/multimodal-finanace-qa/d...   \n",
              "\n",
              "                  question_type question_type_description        file_type  \n",
              "0  Factual Extraction Questions           Low to Moderate       [mp3, mp4]  \n",
              "1   Anomaly Detection Questions                      High  [mp4, pdf, pdf]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-15068320-2c18-4766-abe0-7ec4409bff0a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>answer</th>\n",
              "      <th>audio_citation</th>\n",
              "      <th>question</th>\n",
              "      <th>text_citation</th>\n",
              "      <th>video_citation</th>\n",
              "      <th>source_file</th>\n",
              "      <th>question_type</th>\n",
              "      <th>question_type_description</th>\n",
              "      <th>file_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Gemini is able to understand and explain the v...</td>\n",
              "      <td>[]</td>\n",
              "      <td>What is Gemini able to do with images created ...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[{'file_name': 'Can AI understand new emojis  ...</td>\n",
              "      <td>[gs://mlops-for-genai/multimodal-finanace-qa/d...</td>\n",
              "      <td>Factual Extraction Questions</td>\n",
              "      <td>Low to Moderate</td>\n",
              "      <td>[mp3, mp4]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The company saw a notable decrease in Sales &amp; ...</td>\n",
              "      <td>[]</td>\n",
              "      <td>Was there an unusual shift in the allocation o...</td>\n",
              "      <td>[{'file_name': '2021_Q1_Earnings_Transcript.pd...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[gs://mlops-for-genai/multimodal-finanace-qa/d...</td>\n",
              "      <td>Anomaly Detection Questions</td>\n",
              "      <td>High</td>\n",
              "      <td>[mp4, pdf, pdf]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-15068320-2c18-4766-abe0-7ec4409bff0a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-15068320-2c18-4766-abe0-7ec4409bff0a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-15068320-2c18-4766-abe0-7ec4409bff0a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b82f2d22-e0aa-4b4b-bde2-0f964bb9ad60\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b82f2d22-e0aa-4b4b-bde2-0f964bb9ad60')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b82f2d22-e0aa-4b4b-bde2-0f964bb9ad60 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "combined_df",
              "summary": "{\n  \"name\": \"combined_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"The company saw a notable decrease in Sales & Marketing expenses between 2019 and 2020. This unusual decline was largely attributed to a decrease in travel and entertainment (T&E) expenses, along with paused or rescheduled ad campaigns. Interestingly, this decrease occured alongside a notable increase in R&D expenses during the same timeframe, with the increase primarily due to growth in headcount. This suggests that the company may have strategically reallocated funds from Sales & Marketing to R&D, possibly due to the pandemic and the rising importance of online services.\",\n          \"The speaker argues that citizen assemblies are a good model for public policy because they help break the deadlock of political parties, involve ordinary people and  help them think about practical ways of dealing with the challenges of rapid technological change. He further suggests that the model is particularly effective at working out how to deal with job losses and in addressing the need for universal basic income.\",\n          \"The model was able to accurately guess movie titles, such as \\\"The Breakfast Club,\\\" \\\"Breakfast at Tiffany's,\\\" \\\"Uncut Gems,\\\" \\\"Goldfinger,\\\" \\\"Bottle Rocket,\\\" \\\"The Wizard of Oz,\\\" \\\"Moonrise Kingdom,\\\" and \\\"Forrest Gump,\\\" based on the combination of images and wordplay presented. \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"audio_citation\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Was there an unusual shift in the allocation of expenses between 2019 and 2020?\",\n          \"What are the reasons why the speaker believes a citizen's assembly is a good model for public policy in a time of rapid technological change?\",\n          \"What can be inferred about the model's capabilities based on its performance in the task shown?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text_citation\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"video_citation\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source_file\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question_type\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Anomaly Detection Questions\",\n          \"Synthesis Questions\",\n          \"Factual Extraction Questions\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question_type_description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Low to Moderate\",\n          \"High\",\n          \"Moderate\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"file_type\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Assuming you have three DataFrames: df1, df2, df3\n",
        "# combined_df = pd.concat([df1, df2, df3])\n",
        "\n",
        "# # Display the combined DataFrame\n",
        "# print(combined_df)"
      ],
      "metadata": {
        "id": "psdx17SvETOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # if you have persisted each generation as csv, then you can run this logic\n",
        "\n",
        "# # Path to your folder containing CSV files\n",
        "# folder_path = \"/content/\"\n",
        "\n",
        "\n",
        "# # Initialize an empty DataFrame to store the combined data\n",
        "# combined_df = pd.DataFrame()\n",
        "\n",
        "# # Iterate through all files in the folder\n",
        "# for filename in os.listdir(folder_path):\n",
        "#     if filename.endswith(\".csv\"):  # Consider only CSV files\n",
        "#         file_path = os.path.join(folder_path, filename)\n",
        "#         df = pd.read_csv(file_path)\n",
        "#         combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
        "\n",
        "# combined_df.reset_index(inplace=True)"
      ],
      "metadata": {
        "id": "Um_XQ0TqrdJs"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JH4yb33ervGz",
        "outputId": "1c84ab65-523f-41a6-acbd-6fbe97963128"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rWoig1WsYEj",
        "outputId": "18b9a0fa-afd9-41ea-bf22-652aecf16003"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['answer', 'audio_citation', 'question', 'text_citation',\n",
              "       'video_citation', 'source_file', 'question_type',\n",
              "       'question_type_description', 'file_type'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_column_order = ['question', 'answer', 'question_type',\n",
        "       'question_type_description', 'audio_citation',  'text_citation',\n",
        "       'video_citation', 'source_file', 'file_type' ]\n",
        "\n",
        "# Reorder columns\n",
        "combined_df = combined_df[new_column_order]"
      ],
      "metadata": {
        "id": "_HBzkicasDRr"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "GVabnTphstgR",
        "outputId": "a25a1491-fea4-401f-ddca-7ff041d34c3d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            question  \\\n",
              "0  What is Gemini able to do with images created ...   \n",
              "1  Was there an unusual shift in the allocation o...   \n",
              "\n",
              "                                              answer  \\\n",
              "0  Gemini is able to understand and explain the v...   \n",
              "1  The company saw a notable decrease in Sales & ...   \n",
              "\n",
              "                  question_type question_type_description audio_citation  \\\n",
              "0  Factual Extraction Questions           Low to Moderate             []   \n",
              "1   Anomaly Detection Questions                      High             []   \n",
              "\n",
              "                                       text_citation  \\\n",
              "0                                                 []   \n",
              "1  [{'file_name': '2021_Q1_Earnings_Transcript.pd...   \n",
              "\n",
              "                                      video_citation  \\\n",
              "0  [{'file_name': 'Can AI understand new emojis  ...   \n",
              "1                                                 []   \n",
              "\n",
              "                                         source_file        file_type  \n",
              "0  [gs://mlops-for-genai/multimodal-finanace-qa/d...       [mp3, mp4]  \n",
              "1  [gs://mlops-for-genai/multimodal-finanace-qa/d...  [mp4, pdf, pdf]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-508a9070-9a53-4155-bd35-fc6463618b1a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>question_type</th>\n",
              "      <th>question_type_description</th>\n",
              "      <th>audio_citation</th>\n",
              "      <th>text_citation</th>\n",
              "      <th>video_citation</th>\n",
              "      <th>source_file</th>\n",
              "      <th>file_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is Gemini able to do with images created ...</td>\n",
              "      <td>Gemini is able to understand and explain the v...</td>\n",
              "      <td>Factual Extraction Questions</td>\n",
              "      <td>Low to Moderate</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[{'file_name': 'Can AI understand new emojis  ...</td>\n",
              "      <td>[gs://mlops-for-genai/multimodal-finanace-qa/d...</td>\n",
              "      <td>[mp3, mp4]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Was there an unusual shift in the allocation o...</td>\n",
              "      <td>The company saw a notable decrease in Sales &amp; ...</td>\n",
              "      <td>Anomaly Detection Questions</td>\n",
              "      <td>High</td>\n",
              "      <td>[]</td>\n",
              "      <td>[{'file_name': '2021_Q1_Earnings_Transcript.pd...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[gs://mlops-for-genai/multimodal-finanace-qa/d...</td>\n",
              "      <td>[mp4, pdf, pdf]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-508a9070-9a53-4155-bd35-fc6463618b1a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-508a9070-9a53-4155-bd35-fc6463618b1a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-508a9070-9a53-4155-bd35-fc6463618b1a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-84a7e69e-af38-4d1d-bf2c-1753dbffa26e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-84a7e69e-af38-4d1d-bf2c-1753dbffa26e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-84a7e69e-af38-4d1d-bf2c-1753dbffa26e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "combined_df",
              "summary": "{\n  \"name\": \"combined_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Was there an unusual shift in the allocation of expenses between 2019 and 2020?\",\n          \"What are the reasons why the speaker believes a citizen's assembly is a good model for public policy in a time of rapid technological change?\",\n          \"What can be inferred about the model's capabilities based on its performance in the task shown?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"The company saw a notable decrease in Sales & Marketing expenses between 2019 and 2020. This unusual decline was largely attributed to a decrease in travel and entertainment (T&E) expenses, along with paused or rescheduled ad campaigns. Interestingly, this decrease occured alongside a notable increase in R&D expenses during the same timeframe, with the increase primarily due to growth in headcount. This suggests that the company may have strategically reallocated funds from Sales & Marketing to R&D, possibly due to the pandemic and the rising importance of online services.\",\n          \"The speaker argues that citizen assemblies are a good model for public policy because they help break the deadlock of political parties, involve ordinary people and  help them think about practical ways of dealing with the challenges of rapid technological change. He further suggests that the model is particularly effective at working out how to deal with job losses and in addressing the need for universal basic income.\",\n          \"The model was able to accurately guess movie titles, such as \\\"The Breakfast Club,\\\" \\\"Breakfast at Tiffany's,\\\" \\\"Uncut Gems,\\\" \\\"Goldfinger,\\\" \\\"Bottle Rocket,\\\" \\\"The Wizard of Oz,\\\" \\\"Moonrise Kingdom,\\\" and \\\"Forrest Gump,\\\" based on the combination of images and wordplay presented. \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question_type\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Anomaly Detection Questions\",\n          \"Synthesis Questions\",\n          \"Factual Extraction Questions\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question_type_description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Low to Moderate\",\n          \"High\",\n          \"Moderate\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"audio_citation\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text_citation\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"video_citation\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source_file\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"file_type\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# combined_df.to_csv(\"combined_data.csv\", index=False)"
      ],
      "metadata": {
        "id": "lGslpqWirpsR"
      },
      "execution_count": 33,
      "outputs": []
    }
  ]
}