{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "metadata": {
        "id": "Wz0zOn_GI7bQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [Building Data for Multimodal Question-Answering System]\n",
        "\n",
        "[Change the link]\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_1_5_flash.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fgemini%2Fgetting-started%2Fintro_gemini_1_5_flash.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
        "    </a>\n",
        "  </td>    \n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/getting-started/intro_gemini_1_5_flash.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_1_5_flash.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n"
      ],
      "metadata": {
        "id": "laG9A9JMI9Hr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview\n",
        "\n",
        "[add overview]"
      ],
      "metadata": {
        "id": "jarpUZKLJIm0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[add what you learned in previous notebook and link] - skip if its first\n",
        "\n",
        "\n",
        "[Context of this notebook compared to overall idea]"
      ],
      "metadata": {
        "id": "jUe-0H73JLDI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting Started"
      ],
      "metadata": {
        "id": "8t0pckqNJNvk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Dependencies\n"
      ],
      "metadata": {
        "id": "X5t2fqYfJPv4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70jxt3ckr_tF",
        "outputId": "0e19ae32-6d42-4ba5-ab3e-a894c76c591c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33m  WARNING: The script tb-gcp-uploader is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "! pip3 install --upgrade --user --quiet google-cloud-aiplatform"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Restart runtime\n",
        "\n",
        "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which restarts the current kernel."
      ],
      "metadata": {
        "id": "Km6_hsqGJStw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    import IPython\n",
        "\n",
        "    app = IPython.Application.instance()\n",
        "    app.kernel.do_shutdown(True)"
      ],
      "metadata": {
        "id": "U4EZcC_-sCPz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. ⚠️</b>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "xM3FCVq4JVVT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "If you are running this notebook on Google Colab, run the cell below to authenticate your environment.\n"
      ],
      "metadata": {
        "id": "ju8zRjSUJXbA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set Google Cloud project information and initialize Vertex AI SDK\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
        "\n",
        "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ],
      "metadata": {
        "id": "VhwNQHrPJbEH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ],
      "metadata": {
        "id": "27DlnJX_sFpk"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define project information\n",
        "PROJECT_ID = \"\"  # @param {type:\"string\"}\n",
        "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
        "BUCKET_NAME = \"mlops-for-genai\" # @param {type:\"string\"}\n",
        "# Initialize Vertex AI\n",
        "import vertexai\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "\n",
        "# Initialize cloud storage\n",
        "from google.cloud import storage\n",
        "\n",
        "storage_client = storage.Client(project=PROJECT_ID)\n",
        "bucket = storage_client.bucket(BUCKET_NAME)"
      ],
      "metadata": {
        "id": "2S1-P058sPbL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import libraries\n"
      ],
      "metadata": {
        "id": "CzhLTjLvJfIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython.display\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "from vertexai.generative_models import (\n",
        "    GenerationConfig,\n",
        "    GenerativeModel,\n",
        "    HarmBlockThreshold,\n",
        "    HarmCategory,\n",
        "    Part,\n",
        ")\n",
        "from typing import List\n",
        "from google.cloud.storage import Bucket\n",
        "import json\n",
        "import pandas as pd\n",
        "import os"
      ],
      "metadata": {
        "id": "oQNRQncCsP-d"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the models\n",
        "\n",
        "To learn more about all [Gemini API models on Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-models).\n"
      ],
      "metadata": {
        "id": "-eefl9rrJh3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_ID_PRO = \"gemini-1.5-pro-001\"  # @param {type:\"string\"}\n",
        "MODEL_ID_FLASH = \"gemini-1.5-flash-001\" # @param {type:\"string\"}\n",
        "\n",
        "model_pro = GenerativeModel(MODEL_ID_PRO)\n",
        "model_flash = GenerativeModel(MODEL_ID_FLASH)"
      ],
      "metadata": {
        "id": "Gn05MyADsST2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Add data path"
      ],
      "metadata": {
        "id": "WCTAzZokJkFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prototype_data = \"multimodal-finanace-qa/data/unstructured/prototype/\"  # @param {type:\"string\"}\n",
        "production_data = \"multimodal-finanace-qa/data/unstructured/production/\"  # @param {type:\"string\"}"
      ],
      "metadata": {
        "id": "h8FhKlFWsYCO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Manual Review Process for Multimodal RAG Question-Answer-Citation Pairs\n",
        "\n",
        "**SME Review (1-5 SMEs)**\n",
        "\n",
        "**Thorough Review:**\n",
        "\n",
        "*   **Answer Quality:**  Assess if the generated answer is the most accurate and comprehensive representation of the expected response. Modify if necessary.\n",
        "    *   **Voting:**\n",
        "        *   **Accurate (1/0):** Indicate whether the answer is accurate and relevant.\n",
        "        *   **Comprehensive (1/0):** Indicate whether the answer is comprehensive and addresses all aspects of the question.\n",
        "        *   **Well-written (1/0):** Indicate whether the answer is well-written and easy to understand.\n",
        "\n",
        "*   **Question Clarity:** Evaluate if the generated question effectively captures the intended query. Refine if needed.\n",
        "    *   **Voting:**\n",
        "        *   **Clear (1/0):** Indicate whether the question is clear and unambiguous.\n",
        "        *   **Relevant (1/0):** Indicate whether the question is relevant to the context.\n",
        "        *   **Concise (1/0):** Indicate whether the question is concise and to the point.\n",
        "\n",
        "*   **Citation Validity:** Verify the authenticity and relevance of the provided citation.\n",
        "    *   **Voting:**\n",
        "        *   **Authentic (1/0):** Indicate whether the citation is from a reliable source.\n",
        "        *   **Relevant (1/0):** Indicate whether the citation supports the answer.\n",
        "        *   **Accessible (1/0):** Indicate whether the citation is easily accessible.\n",
        "\n",
        "*   **Question Type Alignment:** Confirm that the assigned 'question_type' accurately reflects the nature of the generated question.\n",
        "    *   **Voting:**\n",
        "        *   **Accurate (1/0):** Indicate whether the question type is accurate.\n",
        "\n",
        "*   **Compliance & Policy Adherence:** Flag any question-answer-citation pairs that violate internal compliance guidelines, policies, or expectations.\n",
        "    *   **Voting:**\n",
        "        *   **Compliant (1/0):** Indicate whether the pair adheres to internal policies.\n",
        "        *   **Sensitive Content (1/0):** Indicate whether the pair contains sensitive or offensive content.\n",
        "        *   **Bias (1/0):** Indicate whether the pair exhibits any bias.\n",
        "\n",
        "*   **Strategies & Policies Adherence:** Evaluate if the question-answer-citation pair aligns with the defined strategies and policies for RAG data generation.\n",
        "    *   **Voting:**\n",
        "        *   **Adheres to Strategies (1/0):** Indicate whether the pair aligns with the defined strategies.\n",
        "        *   **Adheres to Policies (1/0):** Indicate whether the pair adheres to the defined policies.\n",
        "\n",
        "**Additional Voting for all methods**\n",
        "\n",
        "*   **Drop (1/0):** Indicate whether the pair should be discarded entirely.\n",
        "*   **Modify (1/0):** Signal if the pair requires modification.\n",
        "*   **Correct Citation (1/0):** Specify if the citation needs correction.\n",
        "*   **Confidence (1-5):** Indicate the SME's confidence in their evaluation.\n",
        "\n",
        "**Preserve Modified Pairs:** Save the modified question-answer-citation pairs for potential use as few-shot examples in future model fine-tuning.\n",
        "\n",
        "**Remember:**\n",
        "\n",
        "*   The manual review process is crucial for ensuring the quality and reliability of the RAG system's outputs.\n",
        "*   By incorporating diverse SME perspectives and implementing robust review strategies, you can enhance the accuracy, fairness, and overall effectiveness of your LLM-powered RAG system.\n",
        "\n",
        "**Please note:** This markdown serves as a raw template. You may need to further customize it to align with your specific project requirements and internal workflows.\n",
        "\n",
        "Let me know if you have any further questions or would like assistance refining this process!"
      ],
      "metadata": {
        "id": "Tp7eySYPJpeN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Manual Review Process for Multimodal RAG Question-Answer-Citation Pairs\n",
        "\n",
        "**SME Review (1-5 SMEs)**\n",
        "\n",
        "| Review Aspect | Voting Criteria | Description |\n",
        "|---|---|---|\n",
        "| **Answer Quality** | Accurate (1/0) | Is the answer factually correct and pertinent to the question? |\n",
        "|  | Comprehensive (1/0) | Does the answer fully address all aspects of the query? |\n",
        "|  | Well-written (1/0) | Is the answer clear, concise, and grammatically sound? |\n",
        "| **Question Clarity** | Clear (1/0) | Is the question unambiguous and easy to understand? |\n",
        "|  | Relevant (1/0) | Does the question pertain to the given context or topic? |\n",
        "|  | Concise (1/0) | Is the question formulated in a brief and to-the-point manner? |\n",
        "| **Citation Validity** | Authentic (1/0) | Is the citation from a reputable and trustworthy source? |\n",
        "|  | Relevant (1/0) | Does the citation directly support the provided answer? |\n",
        "|  | Accessible (1/0) | Can the citation be easily located and verified? |\n",
        "| **Question Type Alignment** | Accurate (1/0) | Does the assigned 'question_type' correctly reflect the nature of the question? |\n",
        "| **Compliance & Policy Adherence** | Compliant (1/0) | Does the pair adhere to internal guidelines and policies? |\n",
        "|  | Sensitive Content (1/0) | Does the pair contain any potentially offensive or harmful material? |\n",
        "|  | Bias (1/0) | Does the pair exhibit any form of prejudice or discrimination? |\n",
        "| **Strategies & Policies Adherence** | Adheres to Strategies (1/0) | Is the pair aligned with the predefined data generation strategies? |\n",
        "|  | Adheres to Policies (1/0) | Does the pair comply with the established data generation policies? |\n",
        "| **Additional Voting** | Drop (1/0) | Should the pair be removed from the dataset entirely? |\n",
        "|  | Modify (1/0) | Does the pair require adjustments or corrections? |\n",
        "|  | Correct Citation (1/0) | Is the citation inaccurate or in need of revision? |\n",
        "|  | Confidence (1-5) | How confident is the SME in their overall evaluation of the pair? |\n",
        "\n",
        "**Preserve Modified Pairs:** Save the modified question-answer-citation pairs for potential use as few-shot examples in future model fine-tuning.\n",
        "\n",
        "**Remember:**\n",
        "\n",
        "*   The manual review process is crucial for ensuring the quality and reliability of the RAG system's outputs.\n",
        "*   By incorporating diverse SME perspectives and implementing robust review strategies, you can enhance the accuracy, fairness, and overall effectiveness of your LLM-powered RAG system."
      ],
      "metadata": {
        "id": "IF8iCz50Jqhx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Levels of Questions in Multimodal RAG Systems (Financial Context)"
      ],
      "metadata": {
        "id": "PKKo1BDwpi9y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Question Type | Description | Complexity | Reasoning | Examples |\n",
        "|---|---|---|---|---|\n",
        "| Factual Extraction Questions | Seek specific information or facts directly from retrieved multimodal data. | Low to Moderate | Minimal to Basic |  \"What was the company's net income in Q2 2023?\" (from financial report)<br> \"Identify the key trends in the company's stock price over the past year.\" (from financial graph)<br> \"Who is the CEO of the company?\" (from launch video or earnings call audio) |\n",
        "| Synthesis Questions | Require combining information from multiple parts or modalities of retrieved data. | Moderate | Integration of information from various sources. | \"Summarize the company's financial performance for the fiscal year based on the annual report and earnings call transcript.\"<br> \"What are the key features of the new product as highlighted in the launch video and discussed in the earnings call?\" |\n",
        "| Inferential Questions | Require going beyond explicit information and making deductions or drawing conclusions from multimodal data. | High | Logical reasoning, potentially involving cross-modal inference and application of financial knowledge. | \"Based on the CEO's tone in the earnings call and the company's financial performance in the recent quarter, what are the potential challenges the company might be facing?\"<br> \"What is the company's strategic focus for the next year based on the product roadmap presented in the launch video and the discussions in the earnings call?\" |\n",
        "| Multi-hop Reasoning Questions | Involve chaining multiple facts or evidence across modalities to arrive at an answer. | Very High | Complex reasoning across different data types, potentially involving causal or temporal relationships. | \"How did the new product launch, as detailed in the launch video, impact the company's revenue in the subsequent quarter, as reported in the financial statements?\"<br> \"Identify any inconsistencies between the financial projections mentioned in the earnings call and the actual results presented in the quarterly report.\" |\n",
        "| Comparative Questions | Explicitly ask for comparisons between entities, events, or concepts across modalities. | Moderate | Identification and comparison of relevant attributes across different data types. | \"Compare the company's revenue growth in the past two quarters as shown in the financial charts.\"<br> \"How do the features of the newly launched product, as shown in the video, compare to those of the previous generation product mentioned in the last year's annual report?\" |\n",
        "| Temporal Questions | Involve understanding the timeline of events or changes in states across multimodal data. | Moderate | Extraction and alignment of temporal information from various sources. | \"Trace the evolution of the company's product line over the past five years based on launch videos and annual reports.\"<br> \"How has the company's profit margin changed over the last three fiscal years as shown in the financial statements?\" |\n",
        "| Hypothetical Questions | Ask about potential outcomes or scenarios based on multimodal data. | High | Combines information from various modalities with financial knowledge and makes predictions or inferences. | \"If the company were to expand into a new market, as hinted at in the earnings call, what potential impact could it have on its revenue?\"<br> \"What could be the potential challenges if the company decides to discontinue one of its product lines, based on the information in the latest earnings call and product launch videos?\" |\n",
        "| Open-Ended Questions | Do not have a single correct answer, invite opinions, discussions, or creative responses based on multimodal data. | High | Involves synthesis, inference, and potentially generation of novel ideas, drawing from various modalities. | \"What are the key strengths and weaknesses of the company's current business strategy based on all available information?\"<br> \"Discuss the potential risks and opportunities associated with investing in this company.\" |\n",
        "| Code Generation/Debugging Questions (Financial Context) | Target understanding and generation of code or identification of errors, specifically related to financial analysis or modeling. | High | Combines information retrieval from various modalities with logical reasoning about financial code and data. | \"Write a Python script to visualize the company's quarterly revenue trend over the past two years using the data from the financial reports.\"<br> \"Identify any potential errors in the calculation of the company's debt-to-equity ratio in the provided financial spreadsheet.\" |\n",
        "| Ambiguous Questions | Can have multiple interpretations or require clarification, especially when dealing with multimodal data. | High | Identifying ambiguities across different modalities, seeking clarification, or providing multiple interpretations. | \"Tell me about the company's performance.\" (Ambiguous - could refer to financial, operational, or other aspects)<br> \"What is the outlook?\" (Ambiguous - could be financial outlook, product outlook, or market outlook) |\n",
        "| Contextual Questions | Rely on understanding the broader context of a conversation or series of interactions, considering multimodal data. | High | Tracking previous queries and responses across modalities, identifying entities and their relationships. | \"Can you show me a graph illustrating that trend?\" (Contextual - assumes a previous mention of a specific trend)<br> \"Explain the impact of that event on the company's stock price.\" (Contextual - refers to a previously discussed event) |\n",
        "| Subjective Questions | Ask for opinions, preferences, or value judgments based on multimodal data, potentially requiring nuanced understanding of financial implications. | High | Identifying diverse perspectives across modalities, acknowledging subjectivity, and potentially offering a balanced or personalized response. | \"Is the company's current CEO doing a good job?\"<br> \"Should the company consider diversifying its product portfolio?\" |\n",
        "| Creative Questions | Call for imaginative or innovative responses based on multimodal data, potentially involving financial storytelling or idea generation. | Very High | Combining information from various modalities with creative thinking, generating novel connections, or producing original content related to finance. | \"Create a compelling narrative highlighting the company's key achievements and milestones over the years, drawing from launch videos and annual reports.\"<br> \"Propose a new marketing campaign for the recently launched product, incorporating insights from the launch video and target audience analysis in the market research report.\" |\n",
        "| Domain-Specific Questions (Finance) | Pertain to specialized areas within finance, requiring in-depth knowledge and understanding of specific terminology and concepts across modalities. | Varies | Necessitates access to relevant financial documents, potentially specialized language models, and understanding of financial jargon across text, audio, and visual data. | \"Explain the concept of 'discounted cash flow' and how it's used in valuing the company.\"<br> \"Analyze the company's risk exposure based on the information in the financial statements and risk factors discussed in the earnings call.\" |\n",
        "| Counterfactual Questions | Explore \"what if\" scenarios by altering past facts or events. | Very High | Understanding cause-and-effect, simulating alternative realities, predicting outcomes. | \"How would the company's stock price have been affected if they had not acquired that competitor last year, based on the market conditions at that time?\" |\n",
        "| Ethical/Moral Questions | Delve into the ethical or moral implications of a company's actions or decisions. | High | Understanding ethical frameworks, societal norms, and potentially generating nuanced arguments. |  \"Was the company's decision to lay off a significant portion of its workforce during the economic downturn morally justifiable?\" |\n",
        "| Causal Questions | Seek to identify cause-and-effect relationships between events or factors. | High | Disentangling complex relationships, considering multiple variables, identifying confounding factors. | \"What were the key factors that contributed to the company's significant increase in market share over the past two years?\" |\n",
        "| Prediction Questions | Ask for forecasts or predictions about future events or trends. | High | Identifying patterns, trends, and potentially utilizing predictive modeling. | \"Based on the company's current financial performance and market trends, what is the likely outlook for its stock price in the next six months?\" |\n",
        "| Anomaly Detection Questions | Aim to identify unusual or unexpected patterns or data points. | High | Understanding normal patterns and deviations, potentially involving statistical analysis. | \"Are there any unusual fluctuations in the company's cash flow statement that warrant further investigation?\" |"
      ],
      "metadata": {
        "id": "gWP-KY_qpdeP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Generation"
      ],
      "metadata": {
        "id": "umgp-ykxJw2D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Defining Variables\n",
        "\n",
        "question_types_dict = {\n",
        "    \"Factual Extraction Questions\": {\n",
        "        \"Description\": \"Seek specific information or facts directly from retrieved multimodal data.\",\n",
        "        \"Complexity\": \"Low to Moderate\",\n",
        "        \"Reasoning\": \"Minimal to Basic\",\n",
        "        \"Examples\": [\n",
        "            \"What was the company's net income in Q2 2023? (from financial report)\",\n",
        "            \"Identify the key trends in the company's stock price over the past year. (from financial graph)\",\n",
        "            \"Who is the CEO of the company? (from launch video or earnings call audio)\"\n",
        "        ]\n",
        "    },\n",
        "    \"Synthesis Questions\": {\n",
        "        \"Description\": \"Require combining information from multiple parts or modalities of retrieved data.\",\n",
        "        \"Complexity\": \"Moderate\",\n",
        "        \"Reasoning\": \"Integration of information from various sources.\",\n",
        "        \"Examples\": [\n",
        "            \"Summarize the company's financial performance for the fiscal year based on the annual report and earnings call transcript.\",\n",
        "            \"What are the key features of the new product as highlighted in the launch video and discussed in the earnings call?\"\n",
        "        ]\n",
        "    },\n",
        "    \"Inferential Questions\": {\n",
        "        \"Description\": \"Require going beyond explicit information and making deductions or drawing conclusions from multimodal data.\",\n",
        "        \"Complexity\": \"High\",\n",
        "        \"Reasoning\": \"Logical reasoning, potentially involving cross-modal inference and application of financial knowledge.\",\n",
        "        \"Examples\": [\n",
        "            \"Based on the CEO's tone in the earnings call and the company's financial performance in the recent quarter, what are the potential challenges the company might be facing?\",\n",
        "            \"What is the company's strategic focus for the next year based on the product roadmap presented in the launch video and the discussions in the earnings call?\"\n",
        "        ]\n",
        "    },\n",
        "    \"Multi-hop Reasoning Questions\": {\n",
        "        \"Description\": \"Involve chaining multiple facts or evidence across modalities to arrive at an answer.\",\n",
        "        \"Complexity\": \"Very High\",\n",
        "        \"Reasoning\": \"Complex reasoning across different data types, potentially involving causal or temporal relationships.\",\n",
        "        \"Examples\": [\n",
        "            \"How did the new product launch, as detailed in the launch video, impact the company's revenue in the subsequent quarter, as reported in the financial statements?\",\n",
        "            \"Identify any inconsistencies between the financial projections mentioned in the earnings call and the actual results presented in the quarterly report.\"\n",
        "        ]\n",
        "    },\n",
        "    \"Comparative Questions\": {\n",
        "        \"Description\": \"Explicitly ask for comparisons between entities, events, or concepts across modalities.\",\n",
        "        \"Complexity\": \"Moderate\",\n",
        "        \"Reasoning\": \"Identification and comparison of relevant attributes across different data types.\",\n",
        "        \"Examples\": [\n",
        "            \"Compare the company's revenue growth in the past two quarters as shown in the financial charts.\",\n",
        "            \"How do the features of the newly launched product, as shown in the video, compare to those of the previous generation product mentioned in the last year's annual report?\"\n",
        "        ]\n",
        "    },\n",
        "    \"Temporal Questions\": {\n",
        "        \"Description\": \"Involve understanding the timeline of events or changes in states across multimodal data.\",\n",
        "        \"Complexity\": \"Moderate\",\n",
        "        \"Reasoning\": \"Extraction and alignment of temporal information from various sources.\",\n",
        "        \"Examples\": [\n",
        "            \"Trace the evolution of the company's product line over the past five years based on launch videos and annual reports.\",\n",
        "            \"How has the company's profit margin changed over the last three fiscal years as shown in the financial statements?\"\n",
        "        ]\n",
        "    },\n",
        "    \"Hypothetical Questions\": {\n",
        "        \"Description\": \"Ask about potential outcomes or scenarios based on multimodal data.\",\n",
        "        \"Complexity\": \"High\",\n",
        "        \"Reasoning\": \"Combines information from various modalities with financial knowledge and makes predictions or inferences.\",\n",
        "        \"Examples\": [\n",
        "            \"If the company were to expand into a new market, as hinted at in the earnings call, what potential impact could it have on its revenue?\",\n",
        "            \"What could be the potential challenges if the company decides to discontinue one of its product lines, based on the information in the latest earnings call and product launch videos?\"\n",
        "        ]\n",
        "    },\n",
        "    \"Open-Ended Questions\": {\n",
        "        \"Description\": \"Do not have a single correct answer, invite opinions, discussions, or creative responses based on multimodal data.\",\n",
        "        \"Complexity\": \"High\",\n",
        "        \"Reasoning\": \"Involves synthesis, inference, and potentially generation of novel ideas, drawing from various modalities.\",\n",
        "        \"Examples\": [\n",
        "            \"What are the key strengths and weaknesses of the company's current business strategy based on all available information?\",\n",
        "            \"Discuss the potential risks and opportunities associated with investing in this company.\"\n",
        "        ]\n",
        "    },\n",
        "    \"Code Generation/Debugging Questions (Financial Context)\": {\n",
        "        \"Description\": \"Target understanding and generation of code or identification of errors, specifically related to financial analysis or modeling.\",\n",
        "        \"Complexity\": \"High\",\n",
        "        \"Reasoning\": \"Combines information retrieval from various modalities with logical reasoning about financial code and data.\",\n",
        "        \"Examples\": [\n",
        "            \"Write a Python script to visualize the company's quarterly revenue trend over the past two years using the data from the financial reports.\",\n",
        "            \"Identify any potential errors in the calculation of the company's debt-to-equity ratio in the provided financial spreadsheet.\"\n",
        "        ]\n",
        "    },\n",
        "    \"Ambiguous Questions\": {\n",
        "        \"Description\": \"Can have multiple interpretations or require clarification, especially when dealing with multimodal data.\",\n",
        "        \"Complexity\": \"High\",\n",
        "        \"Reasoning\": \"Identifying ambiguities across different modalities, seeking clarification, or providing multiple interpretations.\",\n",
        "        \"Examples\": [\n",
        "            \"Tell me about the company's performance. (Ambiguous - could refer to financial, operational, or other aspects)\",\n",
        "            \"What is the outlook? (Ambiguous - could be financial outlook, product outlook, or market outlook)\"\n",
        "        ]\n",
        "    },\n",
        "    \"Contextual Questions\": {\n",
        "        \"Description\": \"Rely on understanding the broader context of a conversation or series of interactions, considering multimodal data.\",\n",
        "        \"Complexity\": \"High\",\n",
        "        \"Reasoning\": \"Tracking previous queries and responses across modalities, identifying entities and their relationships.\",\n",
        "        \"Examples\": [\n",
        "            \"Can you show me a graph illustrating that trend? (Contextual - assumes a previous mention of a specific trend)\",\n",
        "            \"Explain the impact of that event on the company's stock price. (Contextual - refers to a previously discussed event)\"\n",
        "        ]\n",
        "    },\n",
        "    \"Subjective Questions\": {\n",
        "        \"Description\": \"Ask for opinions, preferences, or value judgments based on multimodal data, potentially requiring nuanced understanding of financial implications.\",\n",
        "        \"Complexity\": \"High\",\n",
        "        \"Reasoning\": \"Identifying diverse perspectives across modalities, acknowledging subjectivity, and potentially offering a balanced or personalized response.\",\n",
        "        \"Examples\": [\n",
        "            \"Is the company's current CEO doing a good job?\",\n",
        "            \"Should the company consider diversifying its product portfolio?\"\n",
        "        ]\n",
        "    },\n",
        "    \"Creative Questions\": {\n",
        "        \"Description\": \"Call for imaginative or innovative responses based on multimodal data, potentially involving financial storytelling or idea generation.\",\n",
        "        \"Complexity\": \"Very High\",\n",
        "        \"Reasoning\": \"Combining information from various modalities with creative thinking, generating novel connections, or producing original content related to finance.\",\n",
        "        \"Examples\": [\n",
        "            \"Create a compelling narrative highlighting the company's key achievements and milestones over the years, drawing from launch videos and annual reports.\",\n",
        "            \"Propose a new marketing campaign for the recently launched product, incorporating insights from the launch video and target audience analysis in the market research report.\"\n",
        "        ]\n",
        "    },\n",
        "    \"Domain-Specific Questions (Finance)\": {\n",
        "        \"Description\": \"Pertain to specialized areas within finance, requiring in-depth knowledge and understanding of specific terminology and concepts across modalities.\",\n",
        "        \"Complexity\": \"Varies\",\n",
        "        \"Reasoning\": \"Necessitates access to relevant financial documents, potentially specialized language models, and understanding of financial jargon across text, audio, and visual data.\",\n",
        "        \"Examples\": [\n",
        "            \"Explain the concept of 'discounted cash flow' and how it's used in valuing the company.\",\n",
        "            \"Analyze the company's risk exposure based on the information in the financial statements and risk factors discussed in the earnings call.\"\n",
        "        ]\n",
        "    },\n",
        "    \"Counterfactual Questions\": {\n",
        "        \"Description\": \"Explore 'what if' scenarios by altering past facts or events.\",\n",
        "        \"Complexity\": \"Very High\",\n",
        "        \"Reasoning\": \"Understanding cause-and-effect, simulating alternative realities, predicting outcomes.\",\n",
        "        \"Example\": [\n",
        "            \"How would the company's stock price have been affected if they had not acquired that competitor last year, based on the market conditions at that time?\"\n",
        "        ]\n",
        "    },\n",
        "    \"Ethical/Moral Questions\": {\n",
        "        \"Description\": \"Delve into the ethical or moral implications of a company's actions or decisions.\",\n",
        "        \"Complexity\": \"High\",\n",
        "        \"Reasoning\": \"Understanding ethical frameworks, societal norms, and potentially generating nuanced arguments.\",\n",
        "        \"Example\": [\n",
        "            \"Was the company's decision to lay off a significant portion of its workforce during the economic downturn morally justifiable?\"\n",
        "        ]\n",
        "    },\n",
        "    \"Causal Questions\": {\n",
        "        \"Description\": \"Seek to identify cause-and-effect relationships between events or factors.\",\n",
        "        \"Complexity\": \"High\",\n",
        "        \"Reasoning\": \"Disentangling complex relationships, considering multiple variables, identifying confounding factors.\",\n",
        "        \"Example\": [\n",
        "            \"What were the key factors that contributed to the company's significant increase in market share over the past two years?\"\n",
        "        ]\n",
        "    },\n",
        "    \"Prediction Questions\": {\n",
        "        \"Description\": \"Ask for forecasts or predictions about future events or trends.\",\n",
        "        \"Complexity\": \"High\",\n",
        "        \"Reasoning\": \"Identifying patterns, trends, and potentially utilizing predictive modeling.\",\n",
        "        \"Example\": [\n",
        "            \"Based on the company's current financial performance and market trends, what is the likely outlook for its stock price in the next six months?\"\n",
        "        ]\n",
        "    },\n",
        "    \"Anomaly Detection Questions\": {\n",
        "        \"Description\": \"Aim to identify unusual or unexpected patterns or data points.\",\n",
        "        \"Complexity\": \"High\",\n",
        "        \"Reasoning\": \"Understanding normal patterns and deviations, potentially involving statistical analysis.\",\n",
        "        \"Example\": [\n",
        "            \"Are there any unusual fluctuations in the company's cash flow statement that warrant further investigation?\"\n",
        "        ]\n",
        "    }\n",
        "}\n",
        "\n",
        "#follows OpenAPI 3.0\n",
        "response_schema_gemini_pro = {\n",
        "  \"type\": \"object\",\n",
        "  \"properties\": {\n",
        "    \"question\": {\n",
        "      \"type\": \"string\",\n",
        "      \"description\": \"The question posed to the files.\"\n",
        "    },\n",
        "    \"answer\": {\n",
        "      \"type\": \"string\",\n",
        "      \"description\": \"The generated answer to the question.\"\n",
        "    },\n",
        "    \"text_citation\": {\n",
        "      \"type\": \"array\",\n",
        "      \"items\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "          \"file_name\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"Name of the PDF file.\"\n",
        "          },\n",
        "          \"page_number\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"Page number in the PDF file.\"\n",
        "          },\n",
        "          \"text\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"Exact text from the PDF file.\"\n",
        "          }\n",
        "        },\n",
        "        \"required\": [\"file_name\", \"page_number\", \"text\"]\n",
        "      },\n",
        "      \"description\": \"List of text citations from PDF files.\"\n",
        "    },\n",
        "    \"audio_citation\": {\n",
        "      \"type\": \"array\",\n",
        "      \"items\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "          \"file_name\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"Name of the MP3 file.\"\n",
        "          },\n",
        "          \"timestamp_range\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"Timestamp range in the MP3 file.\"\n",
        "          },\n",
        "          \"transcript\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"Exact excerpt of transcript from the MP3 file.\"\n",
        "          }\n",
        "        },\n",
        "        \"required\": [\"file_name\", \"timestamp_range\", \"transcript\"]\n",
        "      },\n",
        "      \"description\": \"List of audio citations from MP3 files.\"\n",
        "    },\n",
        "    \"video_citation\": {\n",
        "      \"type\": \"array\",\n",
        "      \"items\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "          \"file_name\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"Name of the MP4 file.\"\n",
        "          },\n",
        "          \"timestamp_range\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"Timestamp range in the MP4 file.\"\n",
        "          },\n",
        "          \"transcript\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"Exact excerpt of transcript from the MP4 file.\"\n",
        "          }\n",
        "        },\n",
        "        \"required\": [\"file_name\", \"timestamp_range\", \"transcript\"]\n",
        "      },\n",
        "      \"description\": \"List of video citations from MP4 files.\"\n",
        "    }\n",
        "  },\n",
        "  \"required\": [\"question\", \"answer\", \"text_citation\", \"audio_citation\", \"video_citation\"]\n",
        "}\n",
        "\n",
        "response_schema_gemini_flash = \"\"\"{{\n",
        "\"question\": \"generated question\",\n",
        "\"answer\": \"generate answer\",\n",
        "\"text_citation\":  [if pdf: list of all text citations. mention all the file name, page_number and exact text in dictionary.]\n",
        "\"audio_citation\": [if mp3: list of all audio citations. mention all the file name, timestamp and exact excerpt of transcript in dictionary.]\n",
        "\"video_citation\": [if mp4: list of all video citations. mention all the file name, timestamp and exact excerpt of transcript in dictionary.]\n",
        "}}\n",
        "\"\"\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "YN5jDbZTyGAF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Defining Prompts\n",
        "\n",
        "# prompt\n",
        "\n",
        "# Fusion Generation Prompt\n",
        "\n",
        "fushion_generation_task_prompt = \"\"\"Task: I need you to generate questions where the answers require synthesizing information across multiple files (PDF, video, and audio). The answer should NOT be found within a single file; it should combine insights from at least two different file types.\n",
        "Example to follow:\n",
        "\n",
        "Consider the following files:\n",
        "* \"Climate Change Impacts\" (PDF)\n",
        "* \"Renewable Energy Solutions\" (Video)\n",
        "* \"Expert Panel on Sustainability\" (Audio)\n",
        "\n",
        "Pay attention to how the concept of 'sustainability' is discussed in both the video and the audio file.\n",
        "\n",
        "Do not generate questions that can be answered with a simple fact or definition. The ideal question should require analysis, comparison, or evaluation across different sources.\n",
        "\n",
        "Generate a questions that meet these criteria.\n",
        "\n",
        "Follow the context and guidlines below:\n",
        "\"\"\"\n",
        "\n",
        "normal_generation_task_prompt = \"\"\"Task: Generate a question, its relevant context, and the corresponding answer based on the provided multimodal data.\n",
        "    Follow the context and guidlines below:\n",
        "    \"\"\"\n",
        "\n",
        "# Guidelines Prompt\n",
        "guidelines_prompt = \"\"\"Guidelines:\n",
        "\n",
        "Question:\n",
        "- Formulate a clear, focused question directly targeting specific information or facts evident in the data.\n",
        "- Ensure alignment with the specified question type and its intended complexity level.\n",
        "- Avoid ambiguous or overly broad questions.\n",
        "- Do not mention \"in this video/audio/pdf\" or anything that reference the filenames in the question.\n",
        "- If the question is based on video, audio, then don't mention \"speaker\" or reference the file.\n",
        "- If the question is something related to time based entity, mention the time values like year, quarters, months, day etc.\n",
        "\n",
        "Answer:\n",
        "- Provide a concise, accurate answer directly addressing the question.\n",
        "- Ensure the answer is fully supported by the context.\n",
        "- If reasoning/inference is involved: demonstrate the logical steps.\n",
        "- If insufficient information: state \"Answer not found in the provided data\" .\n",
        "\n",
        "Citations:\n",
        "- Provide accurate, complete citations including source titles and identifiers (page numbers, timestamps).\n",
        "- Cite multiple sources if applicable.\n",
        "- Follow the Output Format.\n",
        "\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ec5Sb-S_zDCn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Data Generation Helper Functions\n",
        "\n",
        "\n",
        "def generate_questions_and_responses(total_run=1, total_ques_per_run=1,\n",
        "                                     question_types=None, model=\"pro\", fusion_generation=False,\n",
        "                                     gs_path_list=None, response_schema=None):\n",
        "    \"\"\"\n",
        "    Generates questions and responses based on provided parameters.\n",
        "\n",
        "    Args:\n",
        "        total_run (int): The number of outer loops to run.\n",
        "        total_ques_per_run (int): The number of questions to generate per run.\n",
        "        question_types (list): A list of question types to choose from. If None, all types will be used.\n",
        "        model (str): The model to use for generating responses (\"pro\" or \"flash\").\n",
        "        fusion_generation (bool): Whether to use fusion generation.\n",
        "        gs_path_list (list): A list of GCS paths to select files from.\n",
        "        response_schema (dict): The response schema to use.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of generated responses.\n",
        "    \"\"\"\n",
        "\n",
        "    final_data = []\n",
        "\n",
        "    if question_types is None:\n",
        "        question_types = ['Factual Extraction Questions', 'Synthesis Questions', 'Inferential Questions',\n",
        "                          'Multi-hop Reasoning Questions', 'Comparative Questions', 'Temporal Questions',\n",
        "                          'Ethical/Moral Questions', 'Prediction Questions', 'Anomaly Detection Questions']\n",
        "\n",
        "    for outer_logic in range(total_run):\n",
        "        print(\"running count: \",outer_logic+1)\n",
        "        question_type = random.choice(question_types)\n",
        "        print(\"question_type\", question_type)\n",
        "        question_type_description = question_types_dict[question_type]\n",
        "        selected_paths = select_random_gcs_paths_with_mime_types(gs_path_list, (1, total_ques_per_run))\n",
        "        print(\"Selected Files: \", selected_paths)\n",
        "\n",
        "        for inner_logic in range(total_ques_per_run):\n",
        "            try:\n",
        "                response = get_gemini_response_json(\n",
        "                    question_type,\n",
        "                    question_type_description,\n",
        "                    model=model,\n",
        "                    response_schema=response_schema,\n",
        "                    fusion_generation=fusion_generation,\n",
        "                    file_configs=selected_paths\n",
        "                )\n",
        "                response['file_type'] = [each['gcs_path'].split(\".\")[-1] for each in selected_paths]\n",
        "                final_data.append(response)\n",
        "            except Exception as e:\n",
        "                print(\"Error occurred. Skipping. Error: \", e)\n",
        "                continue\n",
        "\n",
        "    return final_data\n",
        "\n",
        "def get_blob_uri(bucket_name: str, blob_name: str) -> str:\n",
        "    \"\"\"Gets the full URI of the blob in Google Cloud Storage.\n",
        "\n",
        "    Args:\n",
        "        bucket_name: The name of the GCS bucket.\n",
        "        blob_name: The name of the blob within the bucket.\n",
        "\n",
        "    Returns:\n",
        "        The full GCS URI (gs://...) of the blob.\n",
        "    \"\"\"\n",
        "    return f\"gs://{bucket_name}/{blob_name}\"\n",
        "\n",
        "\n",
        "def get_gs_paths_for_production_media(bucket: Bucket, production_data: str) -> List[str]:\n",
        "  \"\"\"\n",
        "  Retrieves Google Storage URIs for media files (PDF, MP4, MP3)\n",
        "  within a specified production data prefix.\n",
        "\n",
        "  Args:\n",
        "      bucket: The Google Cloud Storage bucket to search.\n",
        "      production_data: The prefix indicating production data.\n",
        "\n",
        "  Returns:\n",
        "      A list of Google Storage URIs for the matching media files.\n",
        "  \"\"\"\n",
        "\n",
        "  gs_path_list = []\n",
        "  for blob in bucket.list_blobs():\n",
        "    if blob.name.startswith(production_data) and (\n",
        "        blob.name.endswith(\".pdf\") or\n",
        "        blob.name.endswith(\".mp4\") or\n",
        "        blob.name.endswith(\".mp3\")\n",
        "    ):\n",
        "      gs_path_list.append(get_blob_uri(bucket.name, blob.name))\n",
        "\n",
        "  return gs_path_list\n",
        "\n",
        "def select_random_gcs_paths_with_mime_types(gcs_path_list, selection_range):\n",
        "    \"\"\"\n",
        "    Randomly selects GCS paths and returns them with their corresponding MIME types.\n",
        "\n",
        "    Args:\n",
        "        gcs_path_list: A list of GCS paths to choose from.\n",
        "        selection_range: A tuple (min_files, max_files) specifying the\n",
        "                         minimum and maximum number of files to select.\n",
        "\n",
        "    Returns:\n",
        "        A list of dictionaries, each containing a \"gcs_path\" and its \"mime_type\".\n",
        "    \"\"\"\n",
        "\n",
        "    min_files, max_files = selection_range\n",
        "    num_files_to_select = random.randint(min_files, max_files)\n",
        "    selected_paths = random.sample(gcs_path_list, num_files_to_select)\n",
        "\n",
        "    # Map file extensions to MIME types\n",
        "    extension_mime_type_mapping = {\n",
        "        'pdf': 'application/pdf',\n",
        "        'mp3': 'audio/mpeg',\n",
        "        'mp4': 'video/mp4'\n",
        "    }\n",
        "\n",
        "    # Create the final result list\n",
        "    result = []\n",
        "    for path in selected_paths:\n",
        "        _, file_extension = os.path.splitext(path)\n",
        "        file_extension = file_extension[1:].lower()  # Remove the dot and convert to lowercase\n",
        "\n",
        "        mime_type = extension_mime_type_mapping.get(file_extension, 'application/octet-stream')\n",
        "        # Default to 'application/octet-stream' for unknown extensions\n",
        "\n",
        "        result.append({\"gcs_path\": path, \"mime_type\": mime_type})\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "import random\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_gemini_response_json(question_type, question_type_description,\n",
        "                             model=\"flash\", response_schema=None,\n",
        "                             fusion_generation=False,\n",
        "                             file_configs=[]):\n",
        "  # control generation for JSON using Gemini Flash\n",
        "  if fusion_generation:\n",
        "    print(\"Fusion Generation\")\n",
        "    instruction = fushion_generation_task_prompt\n",
        "  else:\n",
        "    print(\"Normal Generation\")\n",
        "    instruction = normal_generation_task_prompt\n",
        "\n",
        "  question_context_answer_prompt = f\"\"\"{instruction}\n",
        "\n",
        "Question Type: {question_type}\n",
        "\n",
        "Question Type Description: {question_type_description}\n",
        "\n",
        "File Sources: {file_configs}\n",
        "\n",
        "{guidelines_prompt}\n",
        "\n",
        "{\"Output Format: \"+response_schema_gemini_flash if model=='flash' else \"\"}\n",
        "\"\"\"\n",
        "\n",
        "  if model == \"pro\":\n",
        "    print(\"Using Gemini 1.5 Pro model for Data Generation with provided OpenAPI schema\")\n",
        "    cg_model = GenerativeModel(\n",
        "        model_name=\"gemini-1.5-pro\",\n",
        "      generation_config=GenerationConfig(\n",
        "          response_mime_type=\"application/json\", response_schema=response_schema\n",
        "      ),\n",
        "    )\n",
        "  elif model == \"flash\":\n",
        "    print(\"Using Gemini 1.5 Flash model for Data Generation with provided schema in prompt\")\n",
        "    cg_model = GenerativeModel(\n",
        "      model_name=\"gemini-1.5-flash\",\n",
        "      generation_config={\"response_mime_type\": \"application/json\"},\n",
        "      # generation_config=generation_config,\n",
        "  )\n",
        "\n",
        "\n",
        "\n",
        "  # Dynamically create Part objects based on file configurations\n",
        "  content = [question_context_answer_prompt]\n",
        "  content.extend([Part.from_uri(config['gcs_path'], mime_type=config['mime_type']) for config in file_configs])\n",
        "\n",
        "  # Add the analysis prompt\n",
        "  # print(question_context_answer_prompt)\n",
        "  content.append(question_context_answer_prompt)\n",
        "\n",
        "  response = cg_model.generate_content(content)\n",
        "\n",
        "  json_response = json.loads(response.text)\n",
        "\n",
        "  json_response[\"source_file\"] = [config['gcs_path'] for config in file_configs]\n",
        "  json_response[\"question_type\"] = question_type\n",
        "  json_response[\"question_type_description\"] = question_type_description['Complexity']\n",
        "\n",
        "  return (json_response)\n",
        "\n",
        "def generate_questions_and_responses(total_run=1, total_ques_per_run=1,\n",
        "                                     min_file_select=1, max_file_select=2,\n",
        "                                     question_types=None, model=\"pro\", fusion_generation=False,\n",
        "                                     gs_path_list=None, response_schema=None,\n",
        "                                     output_format=None, output_path=None):\n",
        "\n",
        "    \"\"\"\n",
        "    Generates questions and responses based on provided parameters.\n",
        "\n",
        "    Args:\n",
        "        total_run (int): The number of outer loops to run.\n",
        "        total_ques_per_run (int): The number of questions to generate per run.\n",
        "        question_types (list): A list of question types to choose from. If None, all types will be used.\n",
        "        model (str): The model to use for generating responses (\"pro\" or \"flash\").\n",
        "        fusion_generation (bool): Whether to use fusion generation.\n",
        "        gs_path_list (list): A list of GCS paths to select files from.\n",
        "        response_schema (dict): The response schema to use.\n",
        "        output_format (str): The desired output format (\"return_df\" or \"output_path\").\n",
        "        output_path (str): The path to save the DataFrame if output_format is \"output_path\".\n",
        "\n",
        "\n",
        "    Returns:\n",
        "        list: A list of generated responses.\n",
        "        pd.DataFrame or None: A DataFrame if output_format is \"return_df\", otherwise None.\n",
        "    \"\"\"\n",
        "\n",
        "    final_data = []\n",
        "\n",
        "    if question_types is None:\n",
        "        question_types = ['Factual Extraction Questions', 'Synthesis Questions', 'Inferential Questions',\n",
        "                          'Multi-hop Reasoning Questions', 'Comparative Questions', 'Temporal Questions',\n",
        "                          'Ethical/Moral Questions', 'Prediction Questions', 'Anomaly Detection Questions']\n",
        "\n",
        "    for outer_logic in range(total_run):\n",
        "        print(\"running count: \",outer_logic+1)\n",
        "        question_type = random.choice(question_types)\n",
        "        print(\"question_type\", question_type)\n",
        "        question_type_description = question_types_dict[question_type]\n",
        "        selected_paths = select_random_gcs_paths_with_mime_types(gs_path_list, (min_file_select,\n",
        "                                                                                max_file_select))\n",
        "        print(\"Selected Files: \", selected_paths)\n",
        "\n",
        "        for inner_logic in range(total_ques_per_run):\n",
        "            try:\n",
        "                response = get_gemini_response_json(\n",
        "                    question_type,\n",
        "                    question_type_description,\n",
        "                    model=model,\n",
        "                    response_schema=response_schema,\n",
        "                    fusion_generation=fusion_generation,\n",
        "                    file_configs=selected_paths\n",
        "                )\n",
        "                response['file_type'] = [each['gcs_path'].split(\".\")[-1] for each in selected_paths]\n",
        "                final_data.append(response)\n",
        "            except Exception as e:\n",
        "                print(\"Error occurred. Skipping. Error: \", e)\n",
        "                continue\n",
        "\n",
        "    if output_format == \"return_df\":\n",
        "        return pd.DataFrame(final_data)\n",
        "    elif output_format == \"save_df\":\n",
        "        print(\"saving the final datafram at: \", output_path)\n",
        "        pd.DataFrame(final_data).to_csv(output_path, index=False)\n",
        "    else:\n",
        "        return final_data  # Default behavior if no output_format is specified"
      ],
      "metadata": {
        "cellView": "form",
        "id": "GXMduitYx8xl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gs_path_list = get_gs_paths_for_production_media(bucket, production_data)"
      ],
      "metadata": {
        "id": "eLB9NuN85n79"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating with Gemini 1.5 Pro"
      ],
      "metadata": {
        "id": "S0nJBRMLoSOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Gemin 1.5 Pro to generate a single question-answer pair with random question-category\n",
        "# selecting atleast 2 or 3 files at a time for all question types\n",
        "# keeping fusion_generation=True, since question generation should fuse the files.\n",
        "\n",
        "pro_results_2_3 = generate_questions_and_responses(\n",
        "    total_run=2,\n",
        "    total_ques_per_run=1,\n",
        "    min_file_select = 2,\n",
        "    max_file_select = 3,\n",
        "    model=\"pro\",\n",
        "    fusion_generation=True,  # Enable fusion generation\n",
        "    gs_path_list=gs_path_list,\n",
        "    response_schema=response_schema_gemini_pro,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2UHmMgf5Ngq",
        "outputId": "cb109885-db1c-40a1-c1d8-21a69fe31b11"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running count:  1\n",
            "question_type Prediction Questions\n",
            "Selected Files:  [{'gcs_path': 'gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/podcast/episode1.mp3', 'mime_type': 'audio/mpeg'}, {'gcs_path': 'gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/reports/2021/quaterly_report/20210728-alphabet-10q.pdf', 'mime_type': 'application/pdf'}, {'gcs_path': 'gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/reports/2022/quaterly_report/goog-10-k-q4-2022.pdf', 'mime_type': 'application/pdf'}]\n",
            "Fusion Generation\n",
            "Using Gemini 1.5 Pro model for Data Generation with provided OpenAPI schema\n",
            "running count:  2\n",
            "question_type Comparative Questions\n",
            "Selected Files:  [{'gcs_path': 'gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/reports/2023/quaterly_report/20230426-alphabet-10q.pdf', 'mime_type': 'application/pdf'}, {'gcs_path': 'gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/reports/2020/quaterly_report/20201030-alphabet-10q.pdf', 'mime_type': 'application/pdf'}]\n",
            "Fusion Generation\n",
            "Using Gemini 1.5 Pro model for Data Generation with provided OpenAPI schema\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Returning df after generation"
      ],
      "metadata": {
        "id": "yKU7Q8ZTocl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Gemin 1.5 Pro to generate a single question-answer pair with random question-category\n",
        "# selecting atleast 2 or 3 files at a time for all question types\n",
        "# keeping fusion_generation=True, since question generation should fuse the files.\n",
        "# returning dataframe rather than dataframe\n",
        "\n",
        "pro_results_2_3_df = generate_questions_and_responses(\n",
        "    total_run=1,\n",
        "    total_ques_per_run=1,\n",
        "    min_file_select = 1,\n",
        "    max_file_select = 1,\n",
        "    model=\"pro\",\n",
        "    # fusion_generation=True,  # Enable fusion generation\n",
        "    gs_path_list=gs_path_list,\n",
        "    response_schema=response_schema_gemini_pro,\n",
        "    output_format='return_df',\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uh2dAX7CD09",
        "outputId": "abb1ba7b-e0af-4d9b-ad47-de4dbaf87254"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running count:  1\n",
            "question_type Ethical/Moral Questions\n",
            "Selected Files:  [{'gcs_path': 'gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/reports/2020/earning_transcript/2020_Q3_Earnings_Transcript.pdf', 'mime_type': 'application/pdf'}]\n",
            "Normal Generation\n",
            "Using Gemini 1.5 Pro model for Data Generation with provided OpenAPI schema\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pro_results_2_3_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "ctIjHh8rCogB",
        "outputId": "ee39fddc-afbf-44eb-cc4d-2716b19a7a4a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              answer audio_citation  \\\n",
              "0  Although the provided data extensively covers ...             []   \n",
              "\n",
              "                                            question  \\\n",
              "0  Given the comparison made between the company'...   \n",
              "\n",
              "                                       text_citation video_citation  \\\n",
              "0  [{'file_name': 'gs://mlops-for-genai/multimoda...             []   \n",
              "\n",
              "                                         source_file            question_type  \\\n",
              "0  [gs://mlops-for-genai/multimodal-finanace-qa/d...  Ethical/Moral Questions   \n",
              "\n",
              "  question_type_description file_type  \n",
              "0                      High     [pdf]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-98752104-6137-4051-a662-05b4f331dee7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>answer</th>\n",
              "      <th>audio_citation</th>\n",
              "      <th>question</th>\n",
              "      <th>text_citation</th>\n",
              "      <th>video_citation</th>\n",
              "      <th>source_file</th>\n",
              "      <th>question_type</th>\n",
              "      <th>question_type_description</th>\n",
              "      <th>file_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Although the provided data extensively covers ...</td>\n",
              "      <td>[]</td>\n",
              "      <td>Given the comparison made between the company'...</td>\n",
              "      <td>[{'file_name': 'gs://mlops-for-genai/multimoda...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[gs://mlops-for-genai/multimodal-finanace-qa/d...</td>\n",
              "      <td>Ethical/Moral Questions</td>\n",
              "      <td>High</td>\n",
              "      <td>[pdf]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-98752104-6137-4051-a662-05b4f331dee7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-98752104-6137-4051-a662-05b4f331dee7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-98752104-6137-4051-a662-05b4f331dee7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "pro_results_2_3_df",
              "summary": "{\n  \"name\": \"pro_results_2_3_df\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Although the provided data extensively covers the company's stance on the DOJ lawsuit and its commitment to user benefits and partnerships, it does not delve into the specifics of potential ethical concerns surrounding payments for placement within search results.  Therefore, I cannot provide an assessment of the ethical implications related to the comparison of their Search partnerships with a cereal brand's payment for supermarket placement based on the given data.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"audio_citation\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Given the comparison made between the company's search partnerships and a cereal brand paying for prominent placement in a supermarket, what are the ethical implications of potentially prioritizing commercial interests over unbiased search results for the user?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text_citation\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"video_citation\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source_file\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question_type\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Ethical/Moral Questions\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question_type_description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"High\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"file_type\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Persisting df after generation"
      ],
      "metadata": {
        "id": "BmdlQsHxohsh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Gemin 1.5 Pro to generate a single question-answer pair with random question-category\n",
        "# selecting atleast 2 or 3 files at a time for all question types\n",
        "# keeping fusion_generation=True, since question generation should fuse the files.\n",
        "# persisting the results in external path\n",
        "\n",
        "pro_results_2_3_csv = generate_questions_and_responses(\n",
        "    total_run=1,\n",
        "    total_ques_per_run=1,\n",
        "    min_file_select = 1,\n",
        "    max_file_select = 2,\n",
        "    model=\"pro\",\n",
        "    fusion_generation=True,  # Enable fusion generation\n",
        "    gs_path_list=gs_path_list,\n",
        "    response_schema=response_schema_gemini_pro,\n",
        "    output_format='save_df',\n",
        "    output_path='/content/run_gen_pro_1112_fushion.csv',\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Swx-QHA5CTyo",
        "outputId": "137920c3-df65-4b1e-a7be-5af93002d518"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running count:  1\n",
            "question_type Multi-hop Reasoning Questions\n",
            "Selected Files:  [{'gcs_path': 'gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/reports/2021/earning_transcript/2021_Q2_Earnings_Transcript.pdf', 'mime_type': 'application/pdf'}, {'gcs_path': 'gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/product_launch/gemini/Googles newest and most capable AI  Gemini.mp4', 'mime_type': 'video/mp4'}]\n",
            "Fusion Generation\n",
            "Using Gemini 1.5 Pro model for Data Generation with provided OpenAPI schema\n",
            "saving the final datafram at:  /content/run_gen_pro_1112_fushion.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Gemin 1.5 Pro to generate a single question-answer pair with random question-category\n",
        "# selecting only one file for all question types\n",
        "# keeping fusion_generation=False, since single file.\n",
        "\n",
        "pro_results_1_1 = generate_questions_and_responses(\n",
        "    total_run=2,\n",
        "    total_ques_per_run=1,\n",
        "    min_file_select = 1,\n",
        "    max_file_select = 1,\n",
        "    model=\"pro\",\n",
        "    gs_path_list=gs_path_list,\n",
        "    response_schema=response_schema_gemini_pro\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AoOPzVj-aG-",
        "outputId": "3f0fd5bd-828f-48fc-aa8a-258bc689ab1a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running count:  1\n",
            "question_type Ethical/Moral Questions\n",
            "Selected Files:  [{'gcs_path': 'gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/reports/2022/earning_transcript/2022_Q3_Earnings_Transcript.pdf', 'mime_type': 'application/pdf'}]\n",
            "Normal Generation\n",
            "Using Gemini 1.5 Pro model for Data Generation with provided OpenAPI schema\n",
            "running count:  2\n",
            "question_type Prediction Questions\n",
            "Selected Files:  [{'gcs_path': 'gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/reports/2021/earning_transcript/2021_Q4_Earnings_Transcript.pdf', 'mime_type': 'application/pdf'}]\n",
            "Normal Generation\n",
            "Using Gemini 1.5 Pro model for Data Generation with provided OpenAPI schema\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating with Gemini 1.5 Flash"
      ],
      "metadata": {
        "id": "GFKmdV1coXz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Gemin 1.5 Flash to generate a single question-answer pair with random question-category\n",
        "# Flash doesn't expect response_schema\n",
        "\n",
        "results_flash_1_1_sysnques = generate_questions_and_responses(\n",
        "    total_run=1,\n",
        "    total_ques_per_run=1,\n",
        "    min_file_select = 1,\n",
        "    max_file_select = 1,\n",
        "    question_types=['Synthesis Questions'],\n",
        "    model=\"flash\",\n",
        "    # fusion_generation=True,  # Enable fusion generation\n",
        "    gs_path_list=gs_path_list\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZ2FfNuc5OoZ",
        "outputId": "418f27ea-6c63-440d-acf6-339ad1ce570b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running count:  1\n",
            "question_type Synthesis Questions\n",
            "Selected Files:  [{'gcs_path': 'gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/product_launch/gemini/Math & physics with AI  Gemini.mp4', 'mime_type': 'video/mp4'}]\n",
            "Normal Generation\n",
            "Using Gemini 1.5 Flash model for Data Generation with provided schema in prompt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Combination"
      ],
      "metadata": {
        "id": "qdRnmg3wrc3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have all the list\n",
        "\n",
        "combined_list = pro_results_2_3 + pro_results_1_1 + results_flash_1_1_sysnques\n",
        "combined_df = pd.DataFrame(combined_list)"
      ],
      "metadata": {
        "id": "ECEgFnmn_Vz0"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "DwvPtloGAASI",
        "outputId": "bdae45a2-f824-4724-bb85-8a81e2280141"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              answer  \\\n",
              "0  Professor Ngaire Woods argues that the advance...   \n",
              "1  In the first quarter of 2023, Alphabet's long-...   \n",
              "\n",
              "                                      audio_citation  \\\n",
              "0  [{'file_name': 'episode1.mp3', 'timestamp_rang...   \n",
              "1                                                 []   \n",
              "\n",
              "                                            question  \\\n",
              "0  How do experts envision the future of governme...   \n",
              "1  How does Alphabet's long-term debt for the fir...   \n",
              "\n",
              "                                       text_citation video_citation  \\\n",
              "0  [{'file_name': '20210728-alphabet-10q.pdf', 'p...             []   \n",
              "1  [{'file_name': '20230426-alphabet-10q.pdf', 'p...             []   \n",
              "\n",
              "                                         source_file          question_type  \\\n",
              "0  [gs://mlops-for-genai/multimodal-finanace-qa/d...   Prediction Questions   \n",
              "1  [gs://mlops-for-genai/multimodal-finanace-qa/d...  Comparative Questions   \n",
              "\n",
              "  question_type_description        file_type  \n",
              "0                      High  [mp3, pdf, pdf]  \n",
              "1                  Moderate       [pdf, pdf]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2cb4ca65-ed68-465d-a4ed-cd75716c822e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>answer</th>\n",
              "      <th>audio_citation</th>\n",
              "      <th>question</th>\n",
              "      <th>text_citation</th>\n",
              "      <th>video_citation</th>\n",
              "      <th>source_file</th>\n",
              "      <th>question_type</th>\n",
              "      <th>question_type_description</th>\n",
              "      <th>file_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Professor Ngaire Woods argues that the advance...</td>\n",
              "      <td>[{'file_name': 'episode1.mp3', 'timestamp_rang...</td>\n",
              "      <td>How do experts envision the future of governme...</td>\n",
              "      <td>[{'file_name': '20210728-alphabet-10q.pdf', 'p...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[gs://mlops-for-genai/multimodal-finanace-qa/d...</td>\n",
              "      <td>Prediction Questions</td>\n",
              "      <td>High</td>\n",
              "      <td>[mp3, pdf, pdf]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In the first quarter of 2023, Alphabet's long-...</td>\n",
              "      <td>[]</td>\n",
              "      <td>How does Alphabet's long-term debt for the fir...</td>\n",
              "      <td>[{'file_name': '20230426-alphabet-10q.pdf', 'p...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[gs://mlops-for-genai/multimodal-finanace-qa/d...</td>\n",
              "      <td>Comparative Questions</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>[pdf, pdf]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2cb4ca65-ed68-465d-a4ed-cd75716c822e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2cb4ca65-ed68-465d-a4ed-cd75716c822e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2cb4ca65-ed68-465d-a4ed-cd75716c822e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9e6da994-4bf2-4333-9862-ddd3554c41f4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9e6da994-4bf2-4333-9862-ddd3554c41f4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9e6da994-4bf2-4333-9862-ddd3554c41f4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "combined_df",
              "summary": "{\n  \"name\": \"combined_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"In the first quarter of 2023, Alphabet's long-term debt decreased to $13,697 million, down from $14,701 million at the end of 2022.  In the nine months ending September 30, 2020, Alphabet's long-term debt increased to $13,902 million, up from $4,554 million at the end of 2019.\",\n          \"Gemini can identify and point out incorrect answers, explain concepts in greater detail, and offer personalized practice problems based on the mistakes made by the student.\",\n          \"Answer not found in the provided data\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"audio_citation\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"How does Alphabet's long-term debt for the first quarter of 2023 compare to the long-term debt at the end of 2019 and 2020?\",\n          \"What are the different features that Gemini can use to assist students with math problems?\",\n          \"Given the company's emphasis on efficiency and resource optimization in the third quarter of 2022, were there any ethical considerations regarding the treatment of employees who may be impacted by these decisions?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text_citation\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"video_citation\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source_file\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question_type\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Comparative Questions\",\n          \"Synthesis Questions\",\n          \"Prediction Questions\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question_type_description\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Moderate\",\n          \"High\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"file_type\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Assuming you have three DataFrames: df1, df2, df3\n",
        "# combined_df = pd.concat([df1, df2, df3])\n",
        "\n",
        "# # Display the combined DataFrame\n",
        "# print(combined_df)"
      ],
      "metadata": {
        "id": "psdx17SvETOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # if you have persisted each generation as csv, then you can run this logic\n",
        "\n",
        "# # Path to your folder containing CSV files\n",
        "# folder_path = \"/content/\"\n",
        "\n",
        "\n",
        "# # Initialize an empty DataFrame to store the combined data\n",
        "# combined_df = pd.DataFrame()\n",
        "\n",
        "# # Iterate through all files in the folder\n",
        "# for filename in os.listdir(folder_path):\n",
        "#     if filename.endswith(\".csv\"):  # Consider only CSV files\n",
        "#         file_path = os.path.join(folder_path, filename)\n",
        "#         df = pd.read_csv(file_path)\n",
        "#         combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
        "\n",
        "# combined_df.reset_index(inplace=True)"
      ],
      "metadata": {
        "id": "Um_XQ0TqrdJs"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total generated row: \", combined_df.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JH4yb33ervGz",
        "outputId": "07c74ac7-de5a-4010-cf27-cd6790c881db"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total generated row:  5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Columns in the combined data: \\n\",\n",
        "      combined_df.columns.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rWoig1WsYEj",
        "outputId": "daee94f0-12dd-42d0-c12b-32dee696f24b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns in the combined data: \n",
            " ['answer', 'audio_citation', 'question', 'text_citation', 'video_citation', 'source_file', 'question_type', 'question_type_description', 'file_type']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_column_order = ['question', 'answer', 'question_type',\n",
        "       'question_type_description', 'audio_citation',  'text_citation',\n",
        "       'video_citation', 'source_file', 'file_type' ]\n",
        "\n",
        "# Reorder columns\n",
        "combined_df = combined_df[new_column_order]"
      ],
      "metadata": {
        "id": "_HBzkicasDRr"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "GVabnTphstgR",
        "outputId": "cd653d3e-e9e0-4f86-d8b1-0e8a29bd5900"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            question  \\\n",
              "0  How do experts envision the future of governme...   \n",
              "1  How does Alphabet's long-term debt for the fir...   \n",
              "\n",
              "                                              answer          question_type  \\\n",
              "0  Professor Ngaire Woods argues that the advance...   Prediction Questions   \n",
              "1  In the first quarter of 2023, Alphabet's long-...  Comparative Questions   \n",
              "\n",
              "  question_type_description  \\\n",
              "0                      High   \n",
              "1                  Moderate   \n",
              "\n",
              "                                      audio_citation  \\\n",
              "0  [{'file_name': 'episode1.mp3', 'timestamp_rang...   \n",
              "1                                                 []   \n",
              "\n",
              "                                       text_citation video_citation  \\\n",
              "0  [{'file_name': '20210728-alphabet-10q.pdf', 'p...             []   \n",
              "1  [{'file_name': '20230426-alphabet-10q.pdf', 'p...             []   \n",
              "\n",
              "                                         source_file        file_type  \n",
              "0  [gs://mlops-for-genai/multimodal-finanace-qa/d...  [mp3, pdf, pdf]  \n",
              "1  [gs://mlops-for-genai/multimodal-finanace-qa/d...       [pdf, pdf]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-17e1d9b8-5e9c-4470-b832-46ea20b669aa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>question_type</th>\n",
              "      <th>question_type_description</th>\n",
              "      <th>audio_citation</th>\n",
              "      <th>text_citation</th>\n",
              "      <th>video_citation</th>\n",
              "      <th>source_file</th>\n",
              "      <th>file_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How do experts envision the future of governme...</td>\n",
              "      <td>Professor Ngaire Woods argues that the advance...</td>\n",
              "      <td>Prediction Questions</td>\n",
              "      <td>High</td>\n",
              "      <td>[{'file_name': 'episode1.mp3', 'timestamp_rang...</td>\n",
              "      <td>[{'file_name': '20210728-alphabet-10q.pdf', 'p...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[gs://mlops-for-genai/multimodal-finanace-qa/d...</td>\n",
              "      <td>[mp3, pdf, pdf]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How does Alphabet's long-term debt for the fir...</td>\n",
              "      <td>In the first quarter of 2023, Alphabet's long-...</td>\n",
              "      <td>Comparative Questions</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>[]</td>\n",
              "      <td>[{'file_name': '20230426-alphabet-10q.pdf', 'p...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[gs://mlops-for-genai/multimodal-finanace-qa/d...</td>\n",
              "      <td>[pdf, pdf]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-17e1d9b8-5e9c-4470-b832-46ea20b669aa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-17e1d9b8-5e9c-4470-b832-46ea20b669aa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-17e1d9b8-5e9c-4470-b832-46ea20b669aa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fead2b0f-3f6c-4d1d-a344-1dfd573ef11a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fead2b0f-3f6c-4d1d-a344-1dfd573ef11a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fead2b0f-3f6c-4d1d-a344-1dfd573ef11a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "combined_df",
              "summary": "{\n  \"name\": \"combined_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"How does Alphabet's long-term debt for the first quarter of 2023 compare to the long-term debt at the end of 2019 and 2020?\",\n          \"What are the different features that Gemini can use to assist students with math problems?\",\n          \"Given the company's emphasis on efficiency and resource optimization in the third quarter of 2022, were there any ethical considerations regarding the treatment of employees who may be impacted by these decisions?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"In the first quarter of 2023, Alphabet's long-term debt decreased to $13,697 million, down from $14,701 million at the end of 2022.  In the nine months ending September 30, 2020, Alphabet's long-term debt increased to $13,902 million, up from $4,554 million at the end of 2019.\",\n          \"Gemini can identify and point out incorrect answers, explain concepts in greater detail, and offer personalized practice problems based on the mistakes made by the student.\",\n          \"Answer not found in the provided data\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question_type\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Comparative Questions\",\n          \"Synthesis Questions\",\n          \"Prediction Questions\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question_type_description\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Moderate\",\n          \"High\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"audio_citation\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text_citation\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"video_citation\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source_file\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"file_type\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding review processes flags"
      ],
      "metadata": {
        "id": "4vPWRmfcophY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "review_process_column_names = [\n",
        "    \"answer_quality_accurate\",\n",
        "    \"answer_quality_comprehensive\",\n",
        "    \"answer_quality_well_written\",\n",
        "    \"question_clarity_clear\",\n",
        "    \"question_clarity_relevant\",\n",
        "    \"question_clarity_concise\",\n",
        "    \"citation_validity_authentic\",\n",
        "    \"citation_validity_relevant\",\n",
        "    \"citation_validity_accessible\",\n",
        "    \"question_type_alignment_accurate\",\n",
        "    \"compliance_policy_adherence_compliant\",\n",
        "    \"compliance_policy_adherence_sensitive_content\",\n",
        "    \"compliance_policy_adherence_bias\",\n",
        "    \"strategies_policies_adherence_adheres_to_strategies\",\n",
        "    \"strategies_policies_adherence_adheres_to_policies\",\n",
        "    \"voting_drop\",\n",
        "    \"voting_modify\",\n",
        "    \"voting_correct_citation\",\n",
        "    \"voting_confidence\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "HObAkoj1hrpA"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_process_df = pd.DataFrame(0, index=range(combined_df.shape[0]),\n",
        "                                 columns=review_process_column_names)"
      ],
      "metadata": {
        "id": "fthLmxU2hxxN"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_review_with_data = pd.concat([combined_df,review_process_df],axis=1)"
      ],
      "metadata": {
        "id": "LE6iXCakhxta"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_review_with_data.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "sWNINNeLjGGG",
        "outputId": "01a11861-b607-41dc-de0c-cc440ca39377"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            question  \\\n",
              "0  How do experts envision the future of governme...   \n",
              "1  How does Alphabet's long-term debt for the fir...   \n",
              "\n",
              "                                              answer          question_type  \\\n",
              "0  Professor Ngaire Woods argues that the advance...   Prediction Questions   \n",
              "1  In the first quarter of 2023, Alphabet's long-...  Comparative Questions   \n",
              "\n",
              "  question_type_description  \\\n",
              "0                      High   \n",
              "1                  Moderate   \n",
              "\n",
              "                                      audio_citation  \\\n",
              "0  [{'file_name': 'episode1.mp3', 'timestamp_rang...   \n",
              "1                                                 []   \n",
              "\n",
              "                                       text_citation video_citation  \\\n",
              "0  [{'file_name': '20210728-alphabet-10q.pdf', 'p...             []   \n",
              "1  [{'file_name': '20230426-alphabet-10q.pdf', 'p...             []   \n",
              "\n",
              "                                         source_file        file_type  \\\n",
              "0  [gs://mlops-for-genai/multimodal-finanace-qa/d...  [mp3, pdf, pdf]   \n",
              "1  [gs://mlops-for-genai/multimodal-finanace-qa/d...       [pdf, pdf]   \n",
              "\n",
              "   answer_quality_accurate  ...  question_type_alignment_accurate  \\\n",
              "0                        0  ...                                 0   \n",
              "1                        0  ...                                 0   \n",
              "\n",
              "   compliance_policy_adherence_compliant  \\\n",
              "0                                      0   \n",
              "1                                      0   \n",
              "\n",
              "   compliance_policy_adherence_sensitive_content  \\\n",
              "0                                              0   \n",
              "1                                              0   \n",
              "\n",
              "   compliance_policy_adherence_bias  \\\n",
              "0                                 0   \n",
              "1                                 0   \n",
              "\n",
              "   strategies_policies_adherence_adheres_to_strategies  \\\n",
              "0                                                  0     \n",
              "1                                                  0     \n",
              "\n",
              "   strategies_policies_adherence_adheres_to_policies  voting_drop  \\\n",
              "0                                                  0            0   \n",
              "1                                                  0            0   \n",
              "\n",
              "   voting_modify  voting_correct_citation  voting_confidence  \n",
              "0              0                        0                  0  \n",
              "1              0                        0                  0  \n",
              "\n",
              "[2 rows x 28 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2735f6f1-c297-474f-b12e-57ede7eee655\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>question_type</th>\n",
              "      <th>question_type_description</th>\n",
              "      <th>audio_citation</th>\n",
              "      <th>text_citation</th>\n",
              "      <th>video_citation</th>\n",
              "      <th>source_file</th>\n",
              "      <th>file_type</th>\n",
              "      <th>answer_quality_accurate</th>\n",
              "      <th>...</th>\n",
              "      <th>question_type_alignment_accurate</th>\n",
              "      <th>compliance_policy_adherence_compliant</th>\n",
              "      <th>compliance_policy_adherence_sensitive_content</th>\n",
              "      <th>compliance_policy_adherence_bias</th>\n",
              "      <th>strategies_policies_adherence_adheres_to_strategies</th>\n",
              "      <th>strategies_policies_adherence_adheres_to_policies</th>\n",
              "      <th>voting_drop</th>\n",
              "      <th>voting_modify</th>\n",
              "      <th>voting_correct_citation</th>\n",
              "      <th>voting_confidence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How do experts envision the future of governme...</td>\n",
              "      <td>Professor Ngaire Woods argues that the advance...</td>\n",
              "      <td>Prediction Questions</td>\n",
              "      <td>High</td>\n",
              "      <td>[{'file_name': 'episode1.mp3', 'timestamp_rang...</td>\n",
              "      <td>[{'file_name': '20210728-alphabet-10q.pdf', 'p...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[gs://mlops-for-genai/multimodal-finanace-qa/d...</td>\n",
              "      <td>[mp3, pdf, pdf]</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How does Alphabet's long-term debt for the fir...</td>\n",
              "      <td>In the first quarter of 2023, Alphabet's long-...</td>\n",
              "      <td>Comparative Questions</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>[]</td>\n",
              "      <td>[{'file_name': '20230426-alphabet-10q.pdf', 'p...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[gs://mlops-for-genai/multimodal-finanace-qa/d...</td>\n",
              "      <td>[pdf, pdf]</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 28 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2735f6f1-c297-474f-b12e-57ede7eee655')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2735f6f1-c297-474f-b12e-57ede7eee655 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2735f6f1-c297-474f-b12e-57ede7eee655');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-31a54a0f-18ec-4679-8dc6-6800b7499415\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-31a54a0f-18ec-4679-8dc6-6800b7499415')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-31a54a0f-18ec-4679-8dc6-6800b7499415 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "final_review_with_data"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# final_review_with_data.to_csv(\"final_review_with_data.csv\", index=False)"
      ],
      "metadata": {
        "id": "lGslpqWirpsR"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Post-Analysis Process for Multimodal RAG Question-Answer-Citation Pairs (Enterprise-Level)\n",
        "\n",
        "### Step 1: Data Consolidation and Calculation\n",
        "\n",
        "1. **Gather SME Reviews:** Collect all completed review forms from the SMEs. Ensure all pairs have been evaluated by the minimum (2) and maximum (5) number of SMEs as defined in the process.\n",
        "\n",
        "2. **Calculate Scores and Flags:**\n",
        "\n",
        "    * **Per-Pair Metrics:** For each question-answer-citation pair, calculate:\n",
        "        * The sum or average for each review aspect (e.g., sum of 'Answer Quality - Accurate' votes).\n",
        "        * The number of times specific flags were raised (e.g., count of 'Drop' votes).\n",
        "        * The average 'Confidence' score.\n",
        "\n",
        "    * **Overall Metrics:** Calculate overall statistics across the entire dataset, such as:\n",
        "        * The percentage of pairs flagged for 'Drop', 'Modify', etc.\n",
        "        * The distribution of 'Confidence' scores.\n",
        "\n",
        "### Step 2: Apply Decision Rules (Threshold-Based)\n",
        "\n",
        "**Note:** The specific thresholds mentioned below should be customized based on your enterprise's risk tolerance, quality standards, and business objectives.\n",
        "\n",
        "1. **Drop Rule:**\n",
        "\n",
        "    * If a pair receives a 'Drop' vote from **more than 50%** of the reviewing SMEs, **automatically drop** the pair from the dataset.\n",
        "    * **Optional:** If a pair receives a high number of 'Drop' votes (e.g., 3 or more), but not the majority, flag it for further review by a senior SME or a quality assurance team.\n",
        "\n",
        "2. **Modify Rule:**\n",
        "\n",
        "    * If a pair receives a 'Modify' vote from **more than 50%** of the reviewing SMEs, **flag it for modification**.\n",
        "    * Each SME who voted for 'Modify' should provide their revised version of the question-answer-citation pair.\n",
        "    * A senior SME or quality assurance team should review the proposed modifications and make the final decision on how to adjust the pair.\n",
        "\n",
        "3. **Hold and Review Rule:**\n",
        "\n",
        "    * If a pair receives a **majority '0' vote** for 'Adheres to Policies' or any other critical compliance aspect, **place the pair on hold**.\n",
        "    * A senior SME or compliance team should thoroughly review the pair to determine whether it can be modified to meet policy requirements or if it should be dropped.\n",
        "\n",
        "4. **Citation Correction Rule:**\n",
        "\n",
        "    * If a pair receives a 'Correct Citation' vote from **more than 50%** of the reviewing SMEs, **flag it for citation correction**.\n",
        "    * A subject matter expert should review and update the citation as needed.\n",
        "\n",
        "5. **Confidence Threshold:**\n",
        "\n",
        "    * If the average 'Confidence' score for a pair is **below a predefined threshold** (e.g., 3 out of 5), **flag the pair for further review**.\n",
        "    * A senior SME or quality assurance team should assess the pair and decide whether to accept it, modify it, or drop it.\n",
        "\n",
        "### Step 3: Iterate and Refine\n",
        "\n",
        "1. **SME Feedback Loop:** Share the post-analysis results and decisions with the SMEs. Gather their feedback on the process, decision rules, and any challenges they encountered during the review.\n",
        "\n",
        "2. **Continuous Improvement:** Use the SME feedback and the overall dataset metrics to refine the review process, adjust thresholds, and improve the data generation strategies and policies.\n",
        "\n",
        "### Additional Considerations for Enterprise Customers\n",
        "\n",
        "* **Scalability:** For large datasets and teams, consider using a review platform or tool to streamline the process, automate calculations, and track progress.\n",
        "\n",
        "* **Data Security and Privacy:** Implement appropriate measures to protect sensitive information in the dataset and ensure compliance with data privacy regulations.\n",
        "\n",
        "* **SME Training and Calibration:** Provide comprehensive training to SMEs on the review process, criteria, and any specific enterprise guidelines. Periodically calibrate the SMEs to ensure consistency in their evaluations.\n",
        "\n",
        "* **Documentation:** Maintain detailed documentation of the review process, decision rules, thresholds, and any modifications made over time.\n",
        "\n",
        "By following this structured post-analysis process, enterprise customers can ensure the high quality, accuracy, and compliance of their multimodal RAG question-answer-citation pairs, leading to improved performance and reliability of their RAG-based applications.\n",
        "\n",
        "**Remember:** The success of this process relies heavily on clear communication, collaboration between SMEs and quality assurance teams, and a commitment to continuous improvement."
      ],
      "metadata": {
        "id": "h8LUn5LFoESG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building and Tuning LLMs for RAG using the Finalized Question-Answer-Citation Pairs\n",
        "\n",
        "Once you have the finalized dataset of question-answer-citation pairs after the rigorous review process, here's a detailed, step-by-step process to build and tune your RAG system and LLMs:\n",
        "\n",
        "**1. Data Preparation and Structuring**\n",
        "\n",
        "* **Format Conversion:** Ensure the data is in a suitable format for your RAG implementation and LLM fine-tuning. Commonly used formats include JSON, CSV, or specific database structures.\n",
        "* **Data Splitting:** Split the dataset into three parts:\n",
        "    * **Training Set:** (Largest portion, e.g., 70-80%) Used to fine-tune the LLM on the task of generating relevant and accurate answers based on the context provided in the citation.\n",
        "    * **Validation Set:** (Smaller portion, e.g., 10-15%) Used to evaluate the model's performance during training and help prevent overfitting.\n",
        "    * **Test Set:** (Held-out portion, e.g., 10-15%) Used for the final evaluation of the model's performance on unseen data.\n",
        "\n",
        "**2. Retrieval System Setup (Building the RAG)**\n",
        "\n",
        "* **Document Store/Vector Database: Vertex Vector Search**\n",
        "    * **Create Index:** Utilize Vertex Vector Search to create an index optimized for efficient similarity search. Specify the dimensionality of your embeddings (determined by the chosen embedding model) and configure the index for optimal performance based on your data volume and query patterns.\n",
        "    * **Data Ingestion:** Ingest your finalized question-answer-citation pairs into Vertex Vector Search.\n",
        "        * **BigQuery Integration:** If your data is stored in BigQuery, you can seamlessly integrate it with Vertex Vector Search using the provided connectors. This enables efficient data loading and synchronization.\n",
        "        * **Preprocessing:** Before ingestion, preprocess your citations (and potentially questions) to ensure they are clean and normalized. This might include text cleaning, tokenization, and other transformations.\n",
        "        * **Embedding Generation:** Use Vertex AI's `text-embeddings` or `multimodal-embeddings` models to generate embeddings for your citations (and questions, if needed). These embeddings capture the semantic meaning of the text and are essential for effective retrieval.\n",
        "        * **Index Updates:**  Implement a mechanism to keep the Vertex Vector Search index up-to-date as new question-answer-citation pairs are added or modified. This ensures that your RAG system always reflects the latest knowledge.\n",
        "\n",
        "* **Retrieval Logic**\n",
        "    * **Query Embedding:** When a user poses a query, convert it into an embedding using the same embedding model used for the citations.\n",
        "    * **Similarity Search:** Perform a similarity search in the Vertex Vector Search index using the query embedding. This will retrieve the top-k most relevant citations based on their semantic similarity to the query.\n",
        "    * **Contextual Filtering (Optional):** If applicable, implement additional filtering or ranking mechanisms based on metadata associated with the citations (e.g., source reliability, date, etc.) to further refine the retrieved context.\n",
        "    * **Cloud Run or Cloud Functions:** Consider using Cloud Run or Cloud Functions to deploy the retrieval logic as a scalable and serverless API endpoint. This enables easy integration with your LLM fine-tuning and serving components.\n",
        "\n",
        "**3. LLM Fine-tuning**\n",
        "\n",
        "* **Model Selection: Gemini 1.5 and Open Models (Gemma)**\n",
        "    * **Gemini 1.5:** Leverage the power of Gemini 1.5 models for their multimodality capabilities and large context window (2M tokens). These models can handle both text and image inputs, enabling you to build a more versatile RAG system.\n",
        "    * **Open Models (Gemma):** Explore different Gemma models (2B, 9B, 27B) to find the best balance between performance and computational resources for your specific use case. Larger models generally offer better performance but require more compute.\n",
        "\n",
        "* **Fine-tuning Framework: Vertex AI Training**\n",
        "    * **Managed Service:** Use Vertex AI Training to streamline the fine-tuning process. It provides a managed environment for training and deploying machine learning models, including LLMs.\n",
        "    * **Hyperparameter Tuning:** Leverage Vertex AI's hyperparameter tuning capabilities to automatically explore different hyperparameter combinations and find the optimal settings for your LLM fine-tuning.\n",
        "\n",
        "* **Data Formatting and Prompt Engineering**\n",
        "    * **Prompt Design:** Carefully craft prompts that guide the LLM to generate relevant and accurate answers based on the retrieved context. The prompt should include:\n",
        "        * Instructions for the LLM (e.g., \"Answer the question based on the provided context.\")\n",
        "        * The user's query\n",
        "        * The retrieved citations\n",
        "    * **Experimentation:** Experiment with different prompt structures and formats to find the most effective approach for your specific task and LLM.\n",
        "    * **BigQuery Feature Store (Optional):** If you have additional features or metadata associated with your question-answer-citation pairs, consider using BigQuery Feature Store to manage and incorporate them into your fine-tuning process.\n",
        "\n",
        "* **Fine-tuning Process**\n",
        "    * **Vertex AI Training Job:** Submit a training job to Vertex AI Training, specifying the pre-trained LLM, the prepared training data, and the desired hyperparameters.\n",
        "    * **Monitoring and Evaluation:** Monitor the training progress and evaluate the model's performance on the validation set using relevant metrics. Adjust hyperparameters or data as needed to improve performance.\n",
        "\n",
        "\n",
        "\n",
        "**4. Integration and Testing**\n",
        "\n",
        "* **Combine Retrieval and LLM:** Integrate the retrieval system with the fine-tuned LLM. When a user poses a query:\n",
        "    * The retrieval system fetches the most relevant citations.\n",
        "    * The LLM generates an answer based on the query and the retrieved citations.\n",
        "* **Thorough Testing:** Rigorously test the integrated system on the held-out test set and various real-world scenarios. Evaluate the system on key metrics like accuracy, relevance, and fluency.\n",
        "\n",
        "**5. Deployment and Monitoring**\n",
        "\n",
        "* **Deployment:** Deploy the RAG system to a suitable environment (cloud, on-premises, etc.) where it can be accessed by users.\n",
        "* **Monitoring and Maintenance:** Continuously monitor the system's performance and gather user feedback. Periodically retrain or fine-tune the models with new data and address any issues that arise.\n",
        "\n",
        "**Thought Process and Key Considerations**\n",
        "\n",
        "* **Data Quality is Paramount:** The quality of your question-answer-citation pairs directly impacts the RAG system's performance. The rigorous review process you've defined is crucial to ensuring high-quality data.\n",
        "* **Retrieval Effectiveness:** The retrieval system plays a critical role in providing relevant context to the LLM. Experiment with different embedding models and retrieval techniques to optimize performance.\n",
        "* **LLM Fine-tuning:** Fine-tuning the LLM on your specific task and data is essential for achieving good results. Carefully consider the choice of pre-trained model, fine-tuning framework, and hyperparameters.\n",
        "* **Evaluation and Iteration:** Continuous evaluation and iteration are key to improving your RAG system. Use a variety of metrics to assess performance, gather user feedback, and make data-driven improvements.\n",
        "* **Enterprise-Specific Considerations:** Consider factors like scalability, security, and compliance when designing and deploying your RAG system in an enterprise environment.\n",
        "\n",
        "Remember that building and tuning an effective RAG system is an iterative process. By carefully following these steps and continuously refining your approach based on data and feedback, you can create a powerful tool for leveraging your knowledge base and providing accurate and informative answers to your users."
      ],
      "metadata": {
        "id": "F3ScYK2T6qEY"
      }
    }
  ]
}